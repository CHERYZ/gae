{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c81566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCM MODEL VAE\n",
    "# 测试修改 lost函数 与 隐变量 z\n",
    "# 将z_log_std -> z_std，去掉log\n",
    "self.z_std = GraphConvolution(input_dim=FLAGS.hidden1,\n",
    "                                    output_dim=FLAGS.hidden2,\n",
    "                                    adj=self.adj,\n",
    "                                    act=lambda x: x,\n",
    "                                    dropout=self.dropout,\n",
    "                                    logging=self.logging)(self.hidden1)\n",
    "\n",
    "self.z = self.z_mean + tf.random_normal([self.n_samples, FLAGS.hidden2]) * self.z_std\n",
    "\n",
    "# Latent loss\n",
    "self.kl = (0.5 / num_nodes) * tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                1 + 2 * tf.log(model.z_std) - tf.square(model.z_mean) -\n",
    "                tf.square(model.z_std), 1\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcefc342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\jupyter\\gae\\gae\\train_debug.py:103: The name tf.sparse_placeholder is deprecated. Please use tf.compat.v1.sparse_placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\jupyter\\gae\\gae\\train_debug.py:106: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\gae-0.0.1-py3.7.egg\\gae\\model.py:31: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\gae-0.0.1-py3.7.egg\\gae\\initializations.py:9: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\gae-0.0.1-py3.7.egg\\gae\\layers.py:29: The name tf.sparse_retain is deprecated. Please use tf.sparse.retain instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorflow\\python\\ops\\sparse_ops.py:1719: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\gae-0.0.1-py3.7.egg\\gae\\layers.py:80: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\gae-0.0.1-py3.7.egg\\gae\\optimizer.py:42: calling weighted_cross_entropy_with_logits (from tensorflow.python.ops.nn_impl) with targets is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "targets is deprecated, use labels instead\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\gae-0.0.1-py3.7.egg\\gae\\optimizer.py:73: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "Epoch: 0001 log_lik= 1.7382555 train_kl= -0.00004 train_loss= 1.73829 train_acc= 0.49590 val_roc= 0.70847 val_ap= 0.74090 time= 2.08216\n",
      "Epoch: 0002 log_lik= 1.4739331 train_kl= -0.00015 train_loss= 1.47409 train_acc= 0.47183 val_roc= 0.69307 val_ap= 0.73578 time= 0.08613\n",
      "Epoch: 0003 log_lik= 1.269342 train_kl= -0.00052 train_loss= 1.26986 train_acc= 0.39381 val_roc= 0.69985 val_ap= 0.74496 time= 0.08096\n",
      "Epoch: 0004 log_lik= 1.121372 train_kl= -0.00092 train_loss= 1.12229 train_acc= 0.35924 val_roc= 0.70819 val_ap= 0.75268 time= 0.08906\n",
      "Epoch: 0005 log_lik= 0.98995245 train_kl= -0.00138 train_loss= 0.99133 train_acc= 0.33653 val_roc= 0.71479 val_ap= 0.75911 time= 0.08449\n",
      "Epoch: 0006 log_lik= 0.8815848 train_kl= -0.00195 train_loss= 0.88353 train_acc= 0.31160 val_roc= 0.72360 val_ap= 0.76675 time= 0.08372\n",
      "Epoch: 0007 log_lik= 0.80670536 train_kl= -0.00262 train_loss= 0.80933 train_acc= 0.28753 val_roc= 0.74503 val_ap= 0.78624 time= 0.08564\n",
      "Epoch: 0008 log_lik= 0.7509126 train_kl= -0.00339 train_loss= 0.75430 train_acc= 0.28486 val_roc= 0.77042 val_ap= 0.80664 time= 0.08416\n",
      "Epoch: 0009 log_lik= 0.71851546 train_kl= -0.00426 train_loss= 0.72278 train_acc= 0.29951 val_roc= 0.78265 val_ap= 0.81225 time= 0.08264\n",
      "Epoch: 0010 log_lik= 0.7055344 train_kl= -0.00517 train_loss= 0.71071 train_acc= 0.28869 val_roc= 0.78180 val_ap= 0.80997 time= 0.08164\n",
      "Epoch: 0011 log_lik= 0.69513905 train_kl= -0.00610 train_loss= 0.70124 train_acc= 0.23245 val_roc= 0.78278 val_ap= 0.81104 time= 0.08264\n",
      "Epoch: 0012 log_lik= 0.6908046 train_kl= -0.00699 train_loss= 0.69780 train_acc= 0.16316 val_roc= 0.80361 val_ap= 0.82396 time= 0.08113\n",
      "Epoch: 0013 log_lik= 0.68462396 train_kl= -0.00779 train_loss= 0.69241 train_acc= 0.15333 val_roc= 0.83069 val_ap= 0.83952 time= 0.08064\n",
      "Epoch: 0014 log_lik= 0.6721885 train_kl= -0.00850 train_loss= 0.68069 train_acc= 0.17370 val_roc= 0.84197 val_ap= 0.84056 time= 0.08035\n",
      "Epoch: 0015 log_lik= 0.6584917 train_kl= -0.00915 train_loss= 0.66764 train_acc= 0.21496 val_roc= 0.84228 val_ap= 0.83814 time= 0.07965\n",
      "Epoch: 0016 log_lik= 0.6435734 train_kl= -0.00974 train_loss= 0.65332 train_acc= 0.23244 val_roc= 0.84101 val_ap= 0.83780 time= 0.08840\n",
      "Epoch: 0017 log_lik= 0.6284616 train_kl= -0.01027 train_loss= 0.63873 train_acc= 0.25551 val_roc= 0.84360 val_ap= 0.83813 time= 0.08164\n",
      "Epoch: 0018 log_lik= 0.61224324 train_kl= -0.01073 train_loss= 0.62298 train_acc= 0.30164 val_roc= 0.84980 val_ap= 0.84007 time= 0.08332\n",
      "Epoch: 0019 log_lik= 0.5967285 train_kl= -0.01110 train_loss= 0.60783 train_acc= 0.34788 val_roc= 0.85236 val_ap= 0.84025 time= 0.08273\n",
      "Epoch: 0020 log_lik= 0.5797545 train_kl= -0.01138 train_loss= 0.59114 train_acc= 0.39378 val_roc= 0.85164 val_ap= 0.84131 time= 0.08429\n",
      "Epoch: 0021 log_lik= 0.5682987 train_kl= -0.01161 train_loss= 0.57990 train_acc= 0.42354 val_roc= 0.85454 val_ap= 0.84738 time= 0.08222\n",
      "Epoch: 0022 log_lik= 0.55819404 train_kl= -0.01183 train_loss= 0.57002 train_acc= 0.44051 val_roc= 0.85833 val_ap= 0.85181 time= 0.08363\n",
      "Epoch: 0023 log_lik= 0.5471987 train_kl= -0.01206 train_loss= 0.55926 train_acc= 0.45777 val_roc= 0.86117 val_ap= 0.85573 time= 0.08331\n",
      "Epoch: 0024 log_lik= 0.5408848 train_kl= -0.01225 train_loss= 0.55314 train_acc= 0.47197 val_roc= 0.86341 val_ap= 0.86042 time= 0.08164\n",
      "Epoch: 0025 log_lik= 0.5336684 train_kl= -0.01239 train_loss= 0.54606 train_acc= 0.48291 val_roc= 0.86676 val_ap= 0.86646 time= 0.08431\n",
      "Epoch: 0026 log_lik= 0.53007406 train_kl= -0.01251 train_loss= 0.54258 train_acc= 0.48240 val_roc= 0.87221 val_ap= 0.87416 time= 0.08264\n",
      "Epoch: 0027 log_lik= 0.5275679 train_kl= -0.01260 train_loss= 0.54017 train_acc= 0.48066 val_roc= 0.87688 val_ap= 0.88028 time= 0.08466\n",
      "Epoch: 0028 log_lik= 0.52164835 train_kl= -0.01265 train_loss= 0.53430 train_acc= 0.48584 val_roc= 0.87966 val_ap= 0.88493 time= 0.08761\n",
      "Epoch: 0029 log_lik= 0.5097837 train_kl= -0.01264 train_loss= 0.52242 train_acc= 0.49408 val_roc= 0.88226 val_ap= 0.88931 time= 0.08184\n",
      "Epoch: 0030 log_lik= 0.50107414 train_kl= -0.01259 train_loss= 0.51366 train_acc= 0.50131 val_roc= 0.88399 val_ap= 0.89127 time= 0.08102\n",
      "Epoch: 0031 log_lik= 0.49485552 train_kl= -0.01253 train_loss= 0.50738 train_acc= 0.50689 val_roc= 0.88599 val_ap= 0.89284 time= 0.08703\n",
      "Epoch: 0032 log_lik= 0.49061388 train_kl= -0.01246 train_loss= 0.50308 train_acc= 0.51092 val_roc= 0.88706 val_ap= 0.89236 time= 0.08396\n",
      "Epoch: 0033 log_lik= 0.4885915 train_kl= -0.01240 train_loss= 0.50099 train_acc= 0.51415 val_roc= 0.88885 val_ap= 0.89277 time= 0.08300\n",
      "Epoch: 0034 log_lik= 0.48893964 train_kl= -0.01233 train_loss= 0.50127 train_acc= 0.51211 val_roc= 0.88972 val_ap= 0.89248 time= 0.08302\n",
      "Epoch: 0035 log_lik= 0.48756698 train_kl= -0.01228 train_loss= 0.49985 train_acc= 0.51425 val_roc= 0.88956 val_ap= 0.89110 time= 0.08096\n",
      "Epoch: 0036 log_lik= 0.48602968 train_kl= -0.01223 train_loss= 0.49826 train_acc= 0.51488 val_roc= 0.88975 val_ap= 0.89040 time= 0.08100\n",
      "Epoch: 0037 log_lik= 0.48335782 train_kl= -0.01219 train_loss= 0.49555 train_acc= 0.52044 val_roc= 0.89040 val_ap= 0.88994 time= 0.09008\n",
      "Epoch: 0038 log_lik= 0.48113668 train_kl= -0.01214 train_loss= 0.49328 train_acc= 0.52336 val_roc= 0.89122 val_ap= 0.89034 time= 0.08099\n",
      "Epoch: 0039 log_lik= 0.47956344 train_kl= -0.01207 train_loss= 0.49164 train_acc= 0.52381 val_roc= 0.89193 val_ap= 0.89172 time= 0.08202\n",
      "Epoch: 0040 log_lik= 0.47775307 train_kl= -0.01200 train_loss= 0.48975 train_acc= 0.52399 val_roc= 0.89161 val_ap= 0.89208 time= 0.08312\n",
      "Epoch: 0041 log_lik= 0.4748422 train_kl= -0.01193 train_loss= 0.48677 train_acc= 0.52652 val_roc= 0.89141 val_ap= 0.89295 time= 0.08483\n",
      "Epoch: 0042 log_lik= 0.47298244 train_kl= -0.01186 train_loss= 0.48485 train_acc= 0.53021 val_roc= 0.89141 val_ap= 0.89395 time= 0.08103\n",
      "Epoch: 0043 log_lik= 0.47099614 train_kl= -0.01181 train_loss= 0.48281 train_acc= 0.53063 val_roc= 0.89147 val_ap= 0.89536 time= 0.08330\n",
      "Epoch: 0044 log_lik= 0.47044533 train_kl= -0.01177 train_loss= 0.48221 train_acc= 0.52828 val_roc= 0.89196 val_ap= 0.89710 time= 0.08472\n",
      "Epoch: 0045 log_lik= 0.46930185 train_kl= -0.01172 train_loss= 0.48102 train_acc= 0.52678 val_roc= 0.89127 val_ap= 0.89707 time= 0.08398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0046 log_lik= 0.4682382 train_kl= -0.01167 train_loss= 0.47991 train_acc= 0.52637 val_roc= 0.89050 val_ap= 0.89706 time= 0.08401\n",
      "Epoch: 0047 log_lik= 0.46622354 train_kl= -0.01164 train_loss= 0.47787 train_acc= 0.52943 val_roc= 0.89082 val_ap= 0.89813 time= 0.08095\n",
      "Epoch: 0048 log_lik= 0.46438277 train_kl= -0.01163 train_loss= 0.47601 train_acc= 0.53103 val_roc= 0.89111 val_ap= 0.89923 time= 0.08251\n",
      "Epoch: 0049 log_lik= 0.46341902 train_kl= -0.01161 train_loss= 0.47503 train_acc= 0.53072 val_roc= 0.89156 val_ap= 0.90008 time= 0.08297\n",
      "Epoch: 0050 log_lik= 0.4628276 train_kl= -0.01159 train_loss= 0.47442 train_acc= 0.53031 val_roc= 0.89203 val_ap= 0.90114 time= 0.08200\n",
      "Epoch: 0051 log_lik= 0.4621205 train_kl= -0.01157 train_loss= 0.47369 train_acc= 0.52898 val_roc= 0.89245 val_ap= 0.90201 time= 0.08299\n",
      "Epoch: 0052 log_lik= 0.46074495 train_kl= -0.01154 train_loss= 0.47228 train_acc= 0.52949 val_roc= 0.89277 val_ap= 0.90330 time= 0.08284\n",
      "Epoch: 0053 log_lik= 0.4593534 train_kl= -0.01151 train_loss= 0.47086 train_acc= 0.52914 val_roc= 0.89302 val_ap= 0.90390 time= 0.08205\n",
      "Epoch: 0054 log_lik= 0.45855746 train_kl= -0.01148 train_loss= 0.47003 train_acc= 0.53081 val_roc= 0.89325 val_ap= 0.90473 time= 0.08609\n",
      "Epoch: 0055 log_lik= 0.4576008 train_kl= -0.01145 train_loss= 0.46905 train_acc= 0.53148 val_roc= 0.89449 val_ap= 0.90639 time= 0.08999\n",
      "Epoch: 0056 log_lik= 0.4569026 train_kl= -0.01142 train_loss= 0.46832 train_acc= 0.53120 val_roc= 0.89520 val_ap= 0.90764 time= 0.08300\n",
      "Epoch: 0057 log_lik= 0.45673352 train_kl= -0.01141 train_loss= 0.46814 train_acc= 0.53213 val_roc= 0.89570 val_ap= 0.90844 time= 0.08010\n",
      "Epoch: 0058 log_lik= 0.4554434 train_kl= -0.01140 train_loss= 0.46684 train_acc= 0.53186 val_roc= 0.89581 val_ap= 0.90869 time= 0.08401\n",
      "Epoch: 0059 log_lik= 0.45475954 train_kl= -0.01139 train_loss= 0.46615 train_acc= 0.53370 val_roc= 0.89646 val_ap= 0.90944 time= 0.08295\n",
      "Epoch: 0060 log_lik= 0.454865 train_kl= -0.01139 train_loss= 0.46625 train_acc= 0.53435 val_roc= 0.89689 val_ap= 0.90981 time= 0.08273\n",
      "Epoch: 0061 log_lik= 0.45435616 train_kl= -0.01139 train_loss= 0.46575 train_acc= 0.53380 val_roc= 0.89757 val_ap= 0.91074 time= 0.08529\n",
      "Epoch: 0062 log_lik= 0.45400602 train_kl= -0.01140 train_loss= 0.46541 train_acc= 0.53577 val_roc= 0.89800 val_ap= 0.91145 time= 0.08598\n",
      "Epoch: 0063 log_lik= 0.45243037 train_kl= -0.01141 train_loss= 0.46384 train_acc= 0.53574 val_roc= 0.89806 val_ap= 0.91157 time= 0.08602\n",
      "Epoch: 0064 log_lik= 0.45228267 train_kl= -0.01141 train_loss= 0.46370 train_acc= 0.53603 val_roc= 0.89787 val_ap= 0.91131 time= 0.08107\n",
      "Epoch: 0065 log_lik= 0.45181054 train_kl= -0.01141 train_loss= 0.46322 train_acc= 0.53659 val_roc= 0.89795 val_ap= 0.91132 time= 0.08002\n",
      "Epoch: 0066 log_lik= 0.45126268 train_kl= -0.01141 train_loss= 0.46267 train_acc= 0.53588 val_roc= 0.89783 val_ap= 0.91101 time= 0.08496\n",
      "Epoch: 0067 log_lik= 0.4505753 train_kl= -0.01142 train_loss= 0.46199 train_acc= 0.53660 val_roc= 0.89770 val_ap= 0.91078 time= 0.08298\n",
      "Epoch: 0068 log_lik= 0.450394 train_kl= -0.01143 train_loss= 0.46183 train_acc= 0.53743 val_roc= 0.89784 val_ap= 0.91128 time= 0.08400\n",
      "Epoch: 0069 log_lik= 0.4499397 train_kl= -0.01144 train_loss= 0.46138 train_acc= 0.53633 val_roc= 0.89776 val_ap= 0.91146 time= 0.08508\n",
      "Epoch: 0070 log_lik= 0.44932857 train_kl= -0.01143 train_loss= 0.46076 train_acc= 0.53860 val_roc= 0.89766 val_ap= 0.91125 time= 0.08499\n",
      "Epoch: 0071 log_lik= 0.44846168 train_kl= -0.01144 train_loss= 0.45990 train_acc= 0.53844 val_roc= 0.89740 val_ap= 0.91088 time= 0.08350\n",
      "Epoch: 0072 log_lik= 0.44802427 train_kl= -0.01145 train_loss= 0.45947 train_acc= 0.53794 val_roc= 0.89611 val_ap= 0.90996 time= 0.08392\n",
      "Epoch: 0073 log_lik= 0.44798577 train_kl= -0.01145 train_loss= 0.45944 train_acc= 0.53779 val_roc= 0.89557 val_ap= 0.90991 time= 0.08550\n",
      "Epoch: 0074 log_lik= 0.44746205 train_kl= -0.01145 train_loss= 0.45892 train_acc= 0.53799 val_roc= 0.89497 val_ap= 0.90990 time= 0.08199\n",
      "Epoch: 0075 log_lik= 0.44730848 train_kl= -0.01144 train_loss= 0.45875 train_acc= 0.53731 val_roc= 0.89523 val_ap= 0.91022 time= 0.08193\n",
      "Epoch: 0076 log_lik= 0.4469282 train_kl= -0.01144 train_loss= 0.45837 train_acc= 0.53696 val_roc= 0.89534 val_ap= 0.91019 time= 0.08454\n",
      "Epoch: 0077 log_lik= 0.44619474 train_kl= -0.01145 train_loss= 0.45764 train_acc= 0.53725 val_roc= 0.89463 val_ap= 0.90971 time= 0.08287\n",
      "Epoch: 0078 log_lik= 0.44599283 train_kl= -0.01146 train_loss= 0.45745 train_acc= 0.53825 val_roc= 0.89400 val_ap= 0.90943 time= 0.08007\n",
      "Epoch: 0079 log_lik= 0.4455628 train_kl= -0.01146 train_loss= 0.45703 train_acc= 0.53820 val_roc= 0.89404 val_ap= 0.90971 time= 0.08599\n",
      "Epoch: 0080 log_lik= 0.4449832 train_kl= -0.01147 train_loss= 0.45645 train_acc= 0.53833 val_roc= 0.89416 val_ap= 0.90993 time= 0.08499\n",
      "Epoch: 0081 log_lik= 0.4448657 train_kl= -0.01148 train_loss= 0.45635 train_acc= 0.53772 val_roc= 0.89472 val_ap= 0.91042 time= 0.08499\n",
      "Epoch: 0082 log_lik= 0.44472802 train_kl= -0.01149 train_loss= 0.45622 train_acc= 0.53833 val_roc= 0.89394 val_ap= 0.90969 time= 0.08105\n",
      "Epoch: 0083 log_lik= 0.44404367 train_kl= -0.01151 train_loss= 0.45555 train_acc= 0.53821 val_roc= 0.89294 val_ap= 0.90918 time= 0.08895\n",
      "Epoch: 0084 log_lik= 0.4438917 train_kl= -0.01152 train_loss= 0.45541 train_acc= 0.53807 val_roc= 0.89286 val_ap= 0.90939 time= 0.08401\n",
      "Epoch: 0085 log_lik= 0.44309843 train_kl= -0.01152 train_loss= 0.45462 train_acc= 0.53792 val_roc= 0.89342 val_ap= 0.90960 time= 0.08300\n",
      "Epoch: 0086 log_lik= 0.44265485 train_kl= -0.01153 train_loss= 0.45418 train_acc= 0.53766 val_roc= 0.89398 val_ap= 0.90997 time= 0.08305\n",
      "Epoch: 0087 log_lik= 0.443065 train_kl= -0.01154 train_loss= 0.45460 train_acc= 0.53822 val_roc= 0.89348 val_ap= 0.90958 time= 0.08103\n",
      "Epoch: 0088 log_lik= 0.44234315 train_kl= -0.01155 train_loss= 0.45389 train_acc= 0.53891 val_roc= 0.89309 val_ap= 0.90920 time= 0.08093\n",
      "Epoch: 0089 log_lik= 0.44175342 train_kl= -0.01155 train_loss= 0.45330 train_acc= 0.53835 val_roc= 0.89315 val_ap= 0.90940 time= 0.08002\n",
      "Epoch: 0090 log_lik= 0.4417829 train_kl= -0.01156 train_loss= 0.45334 train_acc= 0.53847 val_roc= 0.89354 val_ap= 0.90970 time= 0.08100\n",
      "Epoch: 0091 log_lik= 0.44123855 train_kl= -0.01157 train_loss= 0.45281 train_acc= 0.53807 val_roc= 0.89393 val_ap= 0.91019 time= 0.08297\n",
      "Epoch: 0092 log_lik= 0.4415666 train_kl= -0.01158 train_loss= 0.45315 train_acc= 0.53830 val_roc= 0.89413 val_ap= 0.91061 time= 0.08303\n",
      "Epoch: 0093 log_lik= 0.44080135 train_kl= -0.01158 train_loss= 0.45238 train_acc= 0.53826 val_roc= 0.89342 val_ap= 0.90990 time= 0.08899\n",
      "Epoch: 0094 log_lik= 0.44044474 train_kl= -0.01158 train_loss= 0.45203 train_acc= 0.53796 val_roc= 0.89346 val_ap= 0.91036 time= 0.08309\n",
      "Epoch: 0095 log_lik= 0.44003242 train_kl= -0.01159 train_loss= 0.45163 train_acc= 0.53855 val_roc= 0.89437 val_ap= 0.91131 time= 0.08094\n",
      "Epoch: 0096 log_lik= 0.43960804 train_kl= -0.01161 train_loss= 0.45122 train_acc= 0.53739 val_roc= 0.89492 val_ap= 0.91159 time= 0.08392\n",
      "Epoch: 0097 log_lik= 0.43948776 train_kl= -0.01162 train_loss= 0.45111 train_acc= 0.53727 val_roc= 0.89527 val_ap= 0.91188 time= 0.08112\n",
      "Epoch: 0098 log_lik= 0.43928152 train_kl= -0.01162 train_loss= 0.45090 train_acc= 0.53752 val_roc= 0.89513 val_ap= 0.91209 time= 0.08495\n",
      "Epoch: 0099 log_lik= 0.43858045 train_kl= -0.01163 train_loss= 0.45021 train_acc= 0.53790 val_roc= 0.89474 val_ap= 0.91236 time= 0.08200\n",
      "Epoch: 0100 log_lik= 0.43805647 train_kl= -0.01165 train_loss= 0.44970 train_acc= 0.53858 val_roc= 0.89490 val_ap= 0.91267 time= 0.08511\n",
      "Epoch: 0101 log_lik= 0.43771115 train_kl= -0.01166 train_loss= 0.44937 train_acc= 0.53817 val_roc= 0.89572 val_ap= 0.91273 time= 0.08096\n",
      "Epoch: 0102 log_lik= 0.43731752 train_kl= -0.01166 train_loss= 0.44898 train_acc= 0.53809 val_roc= 0.89675 val_ap= 0.91398 time= 0.08295\n",
      "Epoch: 0103 log_lik= 0.43725386 train_kl= -0.01169 train_loss= 0.44894 train_acc= 0.53773 val_roc= 0.89617 val_ap= 0.91390 time= 0.08511\n",
      "Epoch: 0104 log_lik= 0.4364746 train_kl= -0.01170 train_loss= 0.44818 train_acc= 0.53845 val_roc= 0.89578 val_ap= 0.91377 time= 0.08298\n",
      "Epoch: 0105 log_lik= 0.43625844 train_kl= -0.01170 train_loss= 0.44796 train_acc= 0.53788 val_roc= 0.89631 val_ap= 0.91443 time= 0.08495\n",
      "Epoch: 0106 log_lik= 0.43578428 train_kl= -0.01170 train_loss= 0.44749 train_acc= 0.53861 val_roc= 0.89699 val_ap= 0.91478 time= 0.08002\n",
      "Epoch: 0107 log_lik= 0.43554822 train_kl= -0.01172 train_loss= 0.44726 train_acc= 0.53739 val_roc= 0.89738 val_ap= 0.91555 time= 0.08396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0108 log_lik= 0.4352376 train_kl= -0.01173 train_loss= 0.44697 train_acc= 0.53798 val_roc= 0.89747 val_ap= 0.91585 time= 0.08358\n",
      "Epoch: 0109 log_lik= 0.43466038 train_kl= -0.01176 train_loss= 0.44642 train_acc= 0.53845 val_roc= 0.89819 val_ap= 0.91589 time= 0.08185\n",
      "Epoch: 0110 log_lik= 0.4345824 train_kl= -0.01176 train_loss= 0.44635 train_acc= 0.53926 val_roc= 0.89806 val_ap= 0.91600 time= 0.08304\n",
      "Epoch: 0111 log_lik= 0.4342624 train_kl= -0.01176 train_loss= 0.44602 train_acc= 0.53827 val_roc= 0.89847 val_ap= 0.91681 time= 0.08200\n",
      "Epoch: 0112 log_lik= 0.43389 train_kl= -0.01177 train_loss= 0.44566 train_acc= 0.53857 val_roc= 0.89852 val_ap= 0.91714 time= 0.08407\n",
      "Epoch: 0113 log_lik= 0.43395585 train_kl= -0.01180 train_loss= 0.44575 train_acc= 0.54026 val_roc= 0.89845 val_ap= 0.91693 time= 0.08299\n",
      "Epoch: 0114 log_lik= 0.4330358 train_kl= -0.01181 train_loss= 0.44484 train_acc= 0.53995 val_roc= 0.89874 val_ap= 0.91720 time= 0.08502\n",
      "Epoch: 0115 log_lik= 0.4327936 train_kl= -0.01181 train_loss= 0.44461 train_acc= 0.53924 val_roc= 0.89889 val_ap= 0.91756 time= 0.08095\n",
      "Epoch: 0116 log_lik= 0.432395 train_kl= -0.01182 train_loss= 0.44422 train_acc= 0.53971 val_roc= 0.89907 val_ap= 0.91808 time= 0.08204\n",
      "Epoch: 0117 log_lik= 0.43298897 train_kl= -0.01183 train_loss= 0.44482 train_acc= 0.53987 val_roc= 0.89902 val_ap= 0.91784 time= 0.08199\n",
      "Epoch: 0118 log_lik= 0.43238792 train_kl= -0.01184 train_loss= 0.44423 train_acc= 0.54031 val_roc= 0.89906 val_ap= 0.91739 time= 0.09052\n",
      "Epoch: 0119 log_lik= 0.43192798 train_kl= -0.01185 train_loss= 0.44378 train_acc= 0.53934 val_roc= 0.89878 val_ap= 0.91759 time= 0.09696\n",
      "Epoch: 0120 log_lik= 0.43153644 train_kl= -0.01185 train_loss= 0.44339 train_acc= 0.54001 val_roc= 0.89858 val_ap= 0.91750 time= 0.08597\n",
      "Epoch: 0121 log_lik= 0.43139088 train_kl= -0.01186 train_loss= 0.44325 train_acc= 0.53966 val_roc= 0.90003 val_ap= 0.91845 time= 0.08117\n",
      "Epoch: 0122 log_lik= 0.43106022 train_kl= -0.01186 train_loss= 0.44292 train_acc= 0.54088 val_roc= 0.90053 val_ap= 0.91864 time= 0.07979\n",
      "Epoch: 0123 log_lik= 0.43108255 train_kl= -0.01186 train_loss= 0.44294 train_acc= 0.54007 val_roc= 0.89894 val_ap= 0.91773 time= 0.08912\n",
      "Epoch: 0124 log_lik= 0.4309004 train_kl= -0.01187 train_loss= 0.44277 train_acc= 0.53952 val_roc= 0.89923 val_ap= 0.91762 time= 0.08186\n",
      "Epoch: 0125 log_lik= 0.43054938 train_kl= -0.01189 train_loss= 0.44244 train_acc= 0.53933 val_roc= 0.90059 val_ap= 0.91840 time= 0.08399\n",
      "Epoch: 0126 log_lik= 0.4301165 train_kl= -0.01190 train_loss= 0.44202 train_acc= 0.54059 val_roc= 0.90110 val_ap= 0.91889 time= 0.08303\n",
      "Epoch: 0127 log_lik= 0.4304495 train_kl= -0.01190 train_loss= 0.44235 train_acc= 0.53893 val_roc= 0.90009 val_ap= 0.91888 time= 0.08302\n",
      "Epoch: 0128 log_lik= 0.4298608 train_kl= -0.01191 train_loss= 0.44177 train_acc= 0.54019 val_roc= 0.89903 val_ap= 0.91791 time= 0.09297\n",
      "Epoch: 0129 log_lik= 0.42950952 train_kl= -0.01192 train_loss= 0.44143 train_acc= 0.53983 val_roc= 0.89990 val_ap= 0.91790 time= 0.08203\n",
      "Epoch: 0130 log_lik= 0.4290309 train_kl= -0.01193 train_loss= 0.44096 train_acc= 0.53953 val_roc= 0.90065 val_ap= 0.91875 time= 0.08295\n",
      "Epoch: 0131 log_lik= 0.42908445 train_kl= -0.01194 train_loss= 0.44102 train_acc= 0.54023 val_roc= 0.90035 val_ap= 0.91908 time= 0.08249\n",
      "Epoch: 0132 log_lik= 0.4291697 train_kl= -0.01195 train_loss= 0.44112 train_acc= 0.54135 val_roc= 0.89958 val_ap= 0.91848 time= 0.08548\n",
      "Epoch: 0133 log_lik= 0.42849872 train_kl= -0.01195 train_loss= 0.44045 train_acc= 0.54044 val_roc= 0.89930 val_ap= 0.91707 time= 0.08505\n",
      "Epoch: 0134 log_lik= 0.42880204 train_kl= -0.01196 train_loss= 0.44076 train_acc= 0.53904 val_roc= 0.90037 val_ap= 0.91821 time= 0.08294\n",
      "Epoch: 0135 log_lik= 0.42793733 train_kl= -0.01197 train_loss= 0.43991 train_acc= 0.53896 val_roc= 0.90016 val_ap= 0.91896 time= 0.08297\n",
      "Epoch: 0136 log_lik= 0.42796883 train_kl= -0.01198 train_loss= 0.43995 train_acc= 0.54014 val_roc= 0.89909 val_ap= 0.91837 time= 0.08314\n",
      "Epoch: 0137 log_lik= 0.4276453 train_kl= -0.01199 train_loss= 0.43963 train_acc= 0.54121 val_roc= 0.89906 val_ap= 0.91767 time= 0.08194\n",
      "Epoch: 0138 log_lik= 0.42744377 train_kl= -0.01199 train_loss= 0.43943 train_acc= 0.53952 val_roc= 0.89929 val_ap= 0.91781 time= 0.08105\n",
      "Epoch: 0139 log_lik= 0.42705935 train_kl= -0.01199 train_loss= 0.43904 train_acc= 0.53988 val_roc= 0.89967 val_ap= 0.91822 time= 0.08405\n",
      "Epoch: 0140 log_lik= 0.42713276 train_kl= -0.01200 train_loss= 0.43914 train_acc= 0.53989 val_roc= 0.89920 val_ap= 0.91806 time= 0.08296\n",
      "Epoch: 0141 log_lik= 0.42668977 train_kl= -0.01202 train_loss= 0.43871 train_acc= 0.54065 val_roc= 0.89878 val_ap= 0.91760 time= 0.08499\n",
      "Epoch: 0142 log_lik= 0.42630678 train_kl= -0.01202 train_loss= 0.43832 train_acc= 0.53945 val_roc= 0.89893 val_ap= 0.91704 time= 0.08381\n",
      "Epoch: 0143 log_lik= 0.42568818 train_kl= -0.01202 train_loss= 0.43771 train_acc= 0.53978 val_roc= 0.89978 val_ap= 0.91796 time= 0.08184\n",
      "Epoch: 0144 log_lik= 0.42582136 train_kl= -0.01204 train_loss= 0.43786 train_acc= 0.54028 val_roc= 0.89870 val_ap= 0.91749 time= 0.08208\n",
      "Epoch: 0145 log_lik= 0.42585427 train_kl= -0.01205 train_loss= 0.43790 train_acc= 0.54019 val_roc= 0.89886 val_ap= 0.91744 time= 0.08233\n",
      "Epoch: 0146 log_lik= 0.4254795 train_kl= -0.01206 train_loss= 0.43754 train_acc= 0.54031 val_roc= 0.89956 val_ap= 0.91826 time= 0.08196\n",
      "Epoch: 0147 log_lik= 0.4251673 train_kl= -0.01206 train_loss= 0.43723 train_acc= 0.54046 val_roc= 0.89975 val_ap= 0.91790 time= 0.08104\n",
      "Epoch: 0148 log_lik= 0.42496994 train_kl= -0.01207 train_loss= 0.43704 train_acc= 0.53955 val_roc= 0.89956 val_ap= 0.91741 time= 0.08199\n",
      "Epoch: 0149 log_lik= 0.42506242 train_kl= -0.01210 train_loss= 0.43716 train_acc= 0.54027 val_roc= 0.89877 val_ap= 0.91740 time= 0.08300\n",
      "Epoch: 0150 log_lik= 0.42458647 train_kl= -0.01211 train_loss= 0.43669 train_acc= 0.54098 val_roc= 0.89917 val_ap= 0.91824 time= 0.08100\n",
      "Epoch: 0151 log_lik= 0.4245944 train_kl= -0.01211 train_loss= 0.43671 train_acc= 0.54051 val_roc= 0.89985 val_ap= 0.91802 time= 0.08273\n",
      "Epoch: 0152 log_lik= 0.42377993 train_kl= -0.01212 train_loss= 0.43590 train_acc= 0.54038 val_roc= 0.89919 val_ap= 0.91746 time= 0.08363\n",
      "Epoch: 0153 log_lik= 0.4241102 train_kl= -0.01213 train_loss= 0.43624 train_acc= 0.54044 val_roc= 0.89852 val_ap= 0.91712 time= 0.08264\n",
      "Epoch: 0154 log_lik= 0.42390198 train_kl= -0.01214 train_loss= 0.43604 train_acc= 0.53988 val_roc= 0.89893 val_ap= 0.91791 time= 0.08198\n",
      "Epoch: 0155 log_lik= 0.42360616 train_kl= -0.01216 train_loss= 0.43577 train_acc= 0.53985 val_roc= 0.89956 val_ap= 0.91784 time= 0.08505\n",
      "Epoch: 0156 log_lik= 0.4231066 train_kl= -0.01217 train_loss= 0.43527 train_acc= 0.54077 val_roc= 0.89886 val_ap= 0.91700 time= 0.08298\n",
      "Epoch: 0157 log_lik= 0.4233396 train_kl= -0.01217 train_loss= 0.43551 train_acc= 0.54043 val_roc= 0.89825 val_ap= 0.91661 time= 0.08399\n",
      "Epoch: 0158 log_lik= 0.4230441 train_kl= -0.01218 train_loss= 0.43522 train_acc= 0.54066 val_roc= 0.89784 val_ap= 0.91635 time= 0.08304\n",
      "Epoch: 0159 log_lik= 0.42294344 train_kl= -0.01218 train_loss= 0.43513 train_acc= 0.54092 val_roc= 0.89861 val_ap= 0.91687 time= 0.08098\n",
      "Epoch: 0160 log_lik= 0.42262885 train_kl= -0.01221 train_loss= 0.43483 train_acc= 0.53998 val_roc= 0.89861 val_ap= 0.91685 time= 0.08298\n",
      "Epoch: 0161 log_lik= 0.4220964 train_kl= -0.01222 train_loss= 0.43431 train_acc= 0.54127 val_roc= 0.89714 val_ap= 0.91497 time= 0.08104\n",
      "Epoch: 0162 log_lik= 0.42195034 train_kl= -0.01221 train_loss= 0.43416 train_acc= 0.54082 val_roc= 0.89695 val_ap= 0.91494 time= 0.08497\n",
      "Epoch: 0163 log_lik= 0.4218695 train_kl= -0.01222 train_loss= 0.43409 train_acc= 0.54092 val_roc= 0.89780 val_ap= 0.91601 time= 0.08297\n",
      "Epoch: 0164 log_lik= 0.42142555 train_kl= -0.01224 train_loss= 0.43366 train_acc= 0.54129 val_roc= 0.89802 val_ap= 0.91547 time= 0.08105\n",
      "Epoch: 0165 log_lik= 0.4216577 train_kl= -0.01226 train_loss= 0.43392 train_acc= 0.54030 val_roc= 0.89598 val_ap= 0.91370 time= 0.08502\n",
      "Epoch: 0166 log_lik= 0.4212307 train_kl= -0.01224 train_loss= 0.43348 train_acc= 0.54142 val_roc= 0.89507 val_ap= 0.91298 time= 0.08297\n",
      "Epoch: 0167 log_lik= 0.4215726 train_kl= -0.01225 train_loss= 0.43382 train_acc= 0.54115 val_roc= 0.89620 val_ap= 0.91434 time= 0.08111\n",
      "Epoch: 0168 log_lik= 0.42099303 train_kl= -0.01226 train_loss= 0.43325 train_acc= 0.54131 val_roc= 0.89696 val_ap= 0.91482 time= 0.08393\n",
      "Epoch: 0169 log_lik= 0.421027 train_kl= -0.01227 train_loss= 0.43330 train_acc= 0.54057 val_roc= 0.89573 val_ap= 0.91322 time= 0.08906\n",
      "Epoch: 0170 log_lik= 0.42071125 train_kl= -0.01228 train_loss= 0.43299 train_acc= 0.54112 val_roc= 0.89432 val_ap= 0.91222 time= 0.08093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0171 log_lik= 0.4204045 train_kl= -0.01227 train_loss= 0.43268 train_acc= 0.54132 val_roc= 0.89516 val_ap= 0.91302 time= 0.08297\n",
      "Epoch: 0172 log_lik= 0.42036864 train_kl= -0.01228 train_loss= 0.43264 train_acc= 0.54125 val_roc= 0.89572 val_ap= 0.91337 time= 0.08297\n",
      "Epoch: 0173 log_lik= 0.42034078 train_kl= -0.01228 train_loss= 0.43262 train_acc= 0.54180 val_roc= 0.89517 val_ap= 0.91323 time= 0.08282\n",
      "Epoch: 0174 log_lik= 0.42041367 train_kl= -0.01227 train_loss= 0.43268 train_acc= 0.53993 val_roc= 0.89403 val_ap= 0.91227 time= 0.08221\n",
      "Epoch: 0175 log_lik= 0.41987067 train_kl= -0.01228 train_loss= 0.43215 train_acc= 0.54205 val_roc= 0.89338 val_ap= 0.91163 time= 0.08805\n",
      "Epoch: 0176 log_lik= 0.4198651 train_kl= -0.01228 train_loss= 0.43215 train_acc= 0.54095 val_roc= 0.89497 val_ap= 0.91285 time= 0.07994\n",
      "Epoch: 0177 log_lik= 0.4200222 train_kl= -0.01227 train_loss= 0.43229 train_acc= 0.54060 val_roc= 0.89550 val_ap= 0.91283 time= 0.08205\n",
      "Epoch: 0178 log_lik= 0.41965562 train_kl= -0.01228 train_loss= 0.43194 train_acc= 0.54174 val_roc= 0.89401 val_ap= 0.91245 time= 0.08194\n",
      "Epoch: 0179 log_lik= 0.41949555 train_kl= -0.01228 train_loss= 0.43178 train_acc= 0.54209 val_roc= 0.89313 val_ap= 0.91217 time= 0.08024\n",
      "Epoch: 0180 log_lik= 0.41950205 train_kl= -0.01228 train_loss= 0.43179 train_acc= 0.54245 val_roc= 0.89449 val_ap= 0.91215 time= 0.08380\n",
      "Epoch: 0181 log_lik= 0.4192192 train_kl= -0.01229 train_loss= 0.43151 train_acc= 0.54177 val_roc= 0.89458 val_ap= 0.91233 time= 0.08302\n",
      "Epoch: 0182 log_lik= 0.41913274 train_kl= -0.01228 train_loss= 0.43142 train_acc= 0.54151 val_roc= 0.89388 val_ap= 0.91219 time= 0.08195\n",
      "Epoch: 0183 log_lik= 0.41901234 train_kl= -0.01229 train_loss= 0.43131 train_acc= 0.54250 val_roc= 0.89322 val_ap= 0.91152 time= 0.08257\n",
      "Epoch: 0184 log_lik= 0.4191474 train_kl= -0.01230 train_loss= 0.43145 train_acc= 0.54275 val_roc= 0.89452 val_ap= 0.91254 time= 0.08181\n",
      "Epoch: 0185 log_lik= 0.41879824 train_kl= -0.01230 train_loss= 0.43110 train_acc= 0.54198 val_roc= 0.89403 val_ap= 0.91223 time= 0.08205\n",
      "Epoch: 0186 log_lik= 0.4185323 train_kl= -0.01230 train_loss= 0.43083 train_acc= 0.54265 val_roc= 0.89398 val_ap= 0.91190 time= 0.08931\n",
      "Epoch: 0187 log_lik= 0.41900405 train_kl= -0.01230 train_loss= 0.43131 train_acc= 0.54206 val_roc= 0.89437 val_ap= 0.91217 time= 0.08267\n",
      "Epoch: 0188 log_lik= 0.41859576 train_kl= -0.01231 train_loss= 0.43091 train_acc= 0.54250 val_roc= 0.89463 val_ap= 0.91289 time= 0.08302\n",
      "Epoch: 0189 log_lik= 0.4185742 train_kl= -0.01231 train_loss= 0.43089 train_acc= 0.54306 val_roc= 0.89468 val_ap= 0.91284 time= 0.08100\n",
      "Epoch: 0190 log_lik= 0.41823784 train_kl= -0.01232 train_loss= 0.43056 train_acc= 0.54264 val_roc= 0.89482 val_ap= 0.91252 time= 0.08198\n",
      "Epoch: 0191 log_lik= 0.41869247 train_kl= -0.01232 train_loss= 0.43101 train_acc= 0.54140 val_roc= 0.89394 val_ap= 0.91235 time= 0.08196\n",
      "Epoch: 0192 log_lik= 0.41870862 train_kl= -0.01231 train_loss= 0.43102 train_acc= 0.54180 val_roc= 0.89504 val_ap= 0.91290 time= 0.08101\n",
      "Epoch: 0193 log_lik= 0.4182109 train_kl= -0.01232 train_loss= 0.43053 train_acc= 0.54253 val_roc= 0.89503 val_ap= 0.91259 time= 0.08110\n",
      "Epoch: 0194 log_lik= 0.4186778 train_kl= -0.01232 train_loss= 0.43099 train_acc= 0.54197 val_roc= 0.89450 val_ap= 0.91329 time= 0.08296\n",
      "Epoch: 0195 log_lik= 0.41835755 train_kl= -0.01231 train_loss= 0.43067 train_acc= 0.54253 val_roc= 0.89429 val_ap= 0.91275 time= 0.08302\n",
      "Epoch: 0196 log_lik= 0.41826937 train_kl= -0.01232 train_loss= 0.43059 train_acc= 0.54151 val_roc= 0.89503 val_ap= 0.91214 time= 0.08296\n",
      "Epoch: 0197 log_lik= 0.4185221 train_kl= -0.01231 train_loss= 0.43083 train_acc= 0.54226 val_roc= 0.89602 val_ap= 0.91389 time= 0.08197\n",
      "Epoch: 0198 log_lik= 0.41822246 train_kl= -0.01229 train_loss= 0.43052 train_acc= 0.54296 val_roc= 0.89474 val_ap= 0.91319 time= 0.07994\n",
      "Epoch: 0199 log_lik= 0.41826025 train_kl= -0.01230 train_loss= 0.43056 train_acc= 0.54269 val_roc= 0.89398 val_ap= 0.91194 time= 0.08100\n",
      "Epoch: 0200 log_lik= 0.41842255 train_kl= -0.01230 train_loss= 0.43072 train_acc= 0.54228 val_roc= 0.89570 val_ap= 0.91323 time= 0.08443\n",
      "Optimization Finished!\n",
      "Test ROC score: 0.9236809983833161\n",
      "Test AP score: 0.9319760158097183\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 原始模型输出 kl散度、loss\n",
    "# VGAE\n",
    "%run train_debug.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66051b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\jupyter\\gae\\gae\\train_debug.py:103: The name tf.sparse_placeholder is deprecated. Please use tf.compat.v1.sparse_placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\jupyter\\gae\\gae\\train_debug.py:106: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\gae-0.0.1-py3.7.egg\\gae\\model.py:31: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\gae-0.0.1-py3.7.egg\\gae\\initializations.py:9: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\gae-0.0.1-py3.7.egg\\gae\\layers.py:29: The name tf.sparse_retain is deprecated. Please use tf.sparse.retain instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorflow\\python\\ops\\sparse_ops.py:1719: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\gae-0.0.1-py3.7.egg\\gae\\layers.py:80: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\gae-0.0.1-py3.7.egg\\gae\\optimizer.py:106: calling weighted_cross_entropy_with_logits (from tensorflow.python.ops.nn_impl) with targets is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "targets is deprecated, use labels instead\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\gae-0.0.1-py3.7.egg\\gae\\optimizer.py:108: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "Epoch: 0001 log_lik= 1.7882688 train_kl= 0.02679 train_loss= 1.81506 train_acc= 0.49582 val_roc= 0.72271 val_ap= 0.74438 time= 2.03334\n",
      "Epoch: 0002 log_lik= 1.8064908 train_kl= 0.02680 train_loss= 1.83329 train_acc= 0.49009 val_roc= 0.72869 val_ap= 0.76027 time= 0.10102\n",
      "Epoch: 0003 log_lik= 1.7538722 train_kl= 0.02681 train_loss= 1.78068 train_acc= 0.48330 val_roc= 0.77604 val_ap= 0.79144 time= 0.09060\n",
      "Epoch: 0004 log_lik= 1.7637148 train_kl= 0.02682 train_loss= 1.79053 train_acc= 0.48468 val_roc= 0.80682 val_ap= 0.80950 time= 0.08956\n",
      "Epoch: 0005 log_lik= 1.7664732 train_kl= 0.02682 train_loss= 1.79330 train_acc= 0.48429 val_roc= 0.81178 val_ap= 0.81117 time= 0.08166\n",
      "Epoch: 0006 log_lik= 1.7021531 train_kl= 0.02684 train_loss= 1.72900 train_acc= 0.48657 val_roc= 0.82579 val_ap= 0.82874 time= 0.08269\n",
      "Epoch: 0007 log_lik= 1.6693606 train_kl= 0.02687 train_loss= 1.69623 train_acc= 0.49150 val_roc= 0.83822 val_ap= 0.84103 time= 0.08215\n",
      "Epoch: 0008 log_lik= 1.6940535 train_kl= 0.02690 train_loss= 1.72096 train_acc= 0.49308 val_roc= 0.84477 val_ap= 0.84429 time= 0.08164\n",
      "Epoch: 0009 log_lik= 1.6005886 train_kl= 0.02696 train_loss= 1.62754 train_acc= 0.49668 val_roc= 0.84973 val_ap= 0.85088 time= 0.08463\n",
      "Epoch: 0010 log_lik= 1.6089301 train_kl= 0.02702 train_loss= 1.63595 train_acc= 0.49583 val_roc= 0.85311 val_ap= 0.85567 time= 0.08463\n",
      "Epoch: 0011 log_lik= 1.5841532 train_kl= 0.02710 train_loss= 1.61126 train_acc= 0.49451 val_roc= 0.86030 val_ap= 0.85745 time= 0.08563\n",
      "Epoch: 0012 log_lik= 1.5505229 train_kl= 0.02716 train_loss= 1.57768 train_acc= 0.49545 val_roc= 0.86056 val_ap= 0.85493 time= 0.08347\n",
      "Epoch: 0013 log_lik= 1.6057323 train_kl= 0.02721 train_loss= 1.63295 train_acc= 0.49238 val_roc= 0.86663 val_ap= 0.86610 time= 0.08263\n",
      "Epoch: 0014 log_lik= 1.5549377 train_kl= 0.02725 train_loss= 1.58218 train_acc= 0.49852 val_roc= 0.87234 val_ap= 0.87501 time= 0.08171\n",
      "Epoch: 0015 log_lik= 1.5673994 train_kl= 0.02726 train_loss= 1.59466 train_acc= 0.49722 val_roc= 0.87867 val_ap= 0.87833 time= 0.08336\n",
      "Epoch: 0016 log_lik= 1.5016677 train_kl= 0.02724 train_loss= 1.52891 train_acc= 0.49803 val_roc= 0.88305 val_ap= 0.87760 time= 0.08782\n",
      "Epoch: 0017 log_lik= 1.4747753 train_kl= 0.02721 train_loss= 1.50199 train_acc= 0.49848 val_roc= 0.88557 val_ap= 0.87873 time= 0.08164\n",
      "Epoch: 0018 log_lik= 1.5062897 train_kl= 0.02718 train_loss= 1.53347 train_acc= 0.49930 val_roc= 0.89010 val_ap= 0.88457 time= 0.08264\n",
      "Epoch: 0019 log_lik= 1.5219223 train_kl= 0.02715 train_loss= 1.54907 train_acc= 0.49898 val_roc= 0.89274 val_ap= 0.88893 time= 0.08280\n",
      "Epoch: 0020 log_lik= 1.5231272 train_kl= 0.02712 train_loss= 1.55025 train_acc= 0.49997 val_roc= 0.89748 val_ap= 0.89393 time= 0.08227\n",
      "Epoch: 0021 log_lik= 1.4861083 train_kl= 0.02711 train_loss= 1.51322 train_acc= 0.49882 val_roc= 0.90201 val_ap= 0.89898 time= 0.08221\n",
      "Epoch: 0022 log_lik= 1.5056671 train_kl= 0.02711 train_loss= 1.53277 train_acc= 0.49670 val_roc= 0.90380 val_ap= 0.90126 time= 0.08363\n",
      "Epoch: 0023 log_lik= 1.4507637 train_kl= 0.02711 train_loss= 1.47787 train_acc= 0.49554 val_roc= 0.90503 val_ap= 0.90313 time= 0.08067\n",
      "Epoch: 0024 log_lik= 1.4827927 train_kl= 0.02711 train_loss= 1.50991 train_acc= 0.49617 val_roc= 0.90491 val_ap= 0.90574 time= 0.08360\n",
      "Epoch: 0025 log_lik= 1.4715092 train_kl= 0.02712 train_loss= 1.49863 train_acc= 0.50090 val_roc= 0.90507 val_ap= 0.90757 time= 0.08167\n",
      "Epoch: 0026 log_lik= 1.484364 train_kl= 0.02713 train_loss= 1.51150 train_acc= 0.50003 val_roc= 0.90578 val_ap= 0.90879 time= 0.08292\n",
      "Epoch: 0027 log_lik= 1.4857311 train_kl= 0.02715 train_loss= 1.51288 train_acc= 0.50046 val_roc= 0.90701 val_ap= 0.91028 time= 0.08401\n",
      "Epoch: 0028 log_lik= 1.480066 train_kl= 0.02717 train_loss= 1.50724 train_acc= 0.49965 val_roc= 0.90896 val_ap= 0.91288 time= 0.08203\n",
      "Epoch: 0029 log_lik= 1.4795291 train_kl= 0.02719 train_loss= 1.50672 train_acc= 0.50089 val_roc= 0.91051 val_ap= 0.91464 time= 0.08400\n",
      "Epoch: 0030 log_lik= 1.4794097 train_kl= 0.02722 train_loss= 1.50662 train_acc= 0.50248 val_roc= 0.91148 val_ap= 0.91570 time= 0.08194\n",
      "Epoch: 0031 log_lik= 1.4910434 train_kl= 0.02724 train_loss= 1.51828 train_acc= 0.50004 val_roc= 0.91224 val_ap= 0.91678 time= 0.08312\n",
      "Epoch: 0032 log_lik= 1.4402832 train_kl= 0.02725 train_loss= 1.46753 train_acc= 0.49995 val_roc= 0.91233 val_ap= 0.91785 time= 0.08200\n",
      "Epoch: 0033 log_lik= 1.4472575 train_kl= 0.02725 train_loss= 1.47451 train_acc= 0.50145 val_roc= 0.91174 val_ap= 0.91868 time= 0.08193\n",
      "Epoch: 0034 log_lik= 1.4530562 train_kl= 0.02725 train_loss= 1.48030 train_acc= 0.50173 val_roc= 0.91252 val_ap= 0.91984 time= 0.08605\n",
      "Epoch: 0035 log_lik= 1.4759626 train_kl= 0.02724 train_loss= 1.50320 train_acc= 0.50283 val_roc= 0.91302 val_ap= 0.92032 time= 0.08297\n",
      "Epoch: 0036 log_lik= 1.4769967 train_kl= 0.02723 train_loss= 1.50423 train_acc= 0.50162 val_roc= 0.91386 val_ap= 0.92125 time= 0.08513\n",
      "Epoch: 0037 log_lik= 1.4832152 train_kl= 0.02722 train_loss= 1.51044 train_acc= 0.50226 val_roc= 0.91551 val_ap= 0.92239 time= 0.08940\n",
      "Epoch: 0038 log_lik= 1.494397 train_kl= 0.02722 train_loss= 1.52162 train_acc= 0.50184 val_roc= 0.91602 val_ap= 0.92211 time= 0.08199\n",
      "Epoch: 0039 log_lik= 1.4244382 train_kl= 0.02722 train_loss= 1.45166 train_acc= 0.50129 val_roc= 0.91667 val_ap= 0.92338 time= 0.08095\n",
      "Epoch: 0040 log_lik= 1.4344832 train_kl= 0.02721 train_loss= 1.46169 train_acc= 0.50110 val_roc= 0.91733 val_ap= 0.92517 time= 0.08440\n",
      "Epoch: 0041 log_lik= 1.4418197 train_kl= 0.02720 train_loss= 1.46902 train_acc= 0.50111 val_roc= 0.91713 val_ap= 0.92502 time= 0.08265\n",
      "Epoch: 0042 log_lik= 1.4484433 train_kl= 0.02719 train_loss= 1.47564 train_acc= 0.50030 val_roc= 0.91501 val_ap= 0.92255 time= 0.08192\n",
      "Epoch: 0043 log_lik= 1.4344338 train_kl= 0.02719 train_loss= 1.46163 train_acc= 0.50052 val_roc= 0.91330 val_ap= 0.92050 time= 0.08499\n",
      "Epoch: 0044 log_lik= 1.4811893 train_kl= 0.02719 train_loss= 1.50838 train_acc= 0.50033 val_roc= 0.91190 val_ap= 0.91919 time= 0.08202\n",
      "Epoch: 0045 log_lik= 1.429015 train_kl= 0.02720 train_loss= 1.45621 train_acc= 0.50143 val_roc= 0.91132 val_ap= 0.91872 time= 0.08299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0046 log_lik= 1.4456143 train_kl= 0.02720 train_loss= 1.47282 train_acc= 0.50029 val_roc= 0.91243 val_ap= 0.91945 time= 0.08504\n",
      "Epoch: 0047 log_lik= 1.4486187 train_kl= 0.02721 train_loss= 1.47583 train_acc= 0.50186 val_roc= 0.91433 val_ap= 0.92136 time= 0.08296\n",
      "Epoch: 0048 log_lik= 1.4848201 train_kl= 0.02722 train_loss= 1.51204 train_acc= 0.50152 val_roc= 0.91609 val_ap= 0.92245 time= 0.08298\n",
      "Epoch: 0049 log_lik= 1.436134 train_kl= 0.02723 train_loss= 1.46337 train_acc= 0.50160 val_roc= 0.91709 val_ap= 0.92338 time= 0.08305\n",
      "Epoch: 0050 log_lik= 1.4613389 train_kl= 0.02724 train_loss= 1.48858 train_acc= 0.50183 val_roc= 0.91660 val_ap= 0.92301 time= 0.08198\n",
      "Epoch: 0051 log_lik= 1.4674987 train_kl= 0.02725 train_loss= 1.49475 train_acc= 0.50220 val_roc= 0.91516 val_ap= 0.92201 time= 0.08302\n",
      "Epoch: 0052 log_lik= 1.447152 train_kl= 0.02726 train_loss= 1.47441 train_acc= 0.50088 val_roc= 0.91314 val_ap= 0.92093 time= 0.08501\n",
      "Epoch: 0053 log_lik= 1.4503248 train_kl= 0.02726 train_loss= 1.47759 train_acc= 0.50138 val_roc= 0.91161 val_ap= 0.92002 time= 0.08299\n",
      "Epoch: 0054 log_lik= 1.4753325 train_kl= 0.02725 train_loss= 1.50259 train_acc= 0.50212 val_roc= 0.91117 val_ap= 0.91920 time= 0.08300\n",
      "Epoch: 0055 log_lik= 1.4212875 train_kl= 0.02725 train_loss= 1.44853 train_acc= 0.50197 val_roc= 0.91143 val_ap= 0.91906 time= 0.08300\n",
      "Epoch: 0056 log_lik= 1.4467388 train_kl= 0.02724 train_loss= 1.47398 train_acc= 0.50049 val_roc= 0.91258 val_ap= 0.92020 time= 0.08299\n",
      "Epoch: 0057 log_lik= 1.4971287 train_kl= 0.02723 train_loss= 1.52436 train_acc= 0.50169 val_roc= 0.91326 val_ap= 0.92111 time= 0.08499\n",
      "Epoch: 0058 log_lik= 1.4547476 train_kl= 0.02722 train_loss= 1.48197 train_acc= 0.50072 val_roc= 0.91414 val_ap= 0.92190 time= 0.08354\n",
      "Epoch: 0059 log_lik= 1.4580487 train_kl= 0.02722 train_loss= 1.48527 train_acc= 0.50164 val_roc= 0.91375 val_ap= 0.92188 time= 0.08294\n",
      "Epoch: 0060 log_lik= 1.4396356 train_kl= 0.02722 train_loss= 1.46686 train_acc= 0.50150 val_roc= 0.91311 val_ap= 0.92190 time= 0.08194\n",
      "Epoch: 0061 log_lik= 1.4293674 train_kl= 0.02722 train_loss= 1.45659 train_acc= 0.50300 val_roc= 0.91278 val_ap= 0.92143 time= 0.08505\n",
      "Epoch: 0062 log_lik= 1.4355066 train_kl= 0.02722 train_loss= 1.46273 train_acc= 0.50195 val_roc= 0.91298 val_ap= 0.92187 time= 0.08199\n",
      "Epoch: 0063 log_lik= 1.4350182 train_kl= 0.02722 train_loss= 1.46224 train_acc= 0.50190 val_roc= 0.91330 val_ap= 0.92201 time= 0.08301\n",
      "Epoch: 0064 log_lik= 1.4450202 train_kl= 0.02722 train_loss= 1.47224 train_acc= 0.50205 val_roc= 0.91450 val_ap= 0.92270 time= 0.08302\n",
      "Epoch: 0065 log_lik= 1.414032 train_kl= 0.02722 train_loss= 1.44125 train_acc= 0.50157 val_roc= 0.91625 val_ap= 0.92369 time= 0.08300\n",
      "Epoch: 0066 log_lik= 1.4376988 train_kl= 0.02723 train_loss= 1.46493 train_acc= 0.50011 val_roc= 0.91703 val_ap= 0.92401 time= 0.08395\n",
      "Epoch: 0067 log_lik= 1.438585 train_kl= 0.02724 train_loss= 1.46582 train_acc= 0.50164 val_roc= 0.91680 val_ap= 0.92440 time= 0.08249\n",
      "Epoch: 0068 log_lik= 1.4410377 train_kl= 0.02725 train_loss= 1.46829 train_acc= 0.50294 val_roc= 0.91493 val_ap= 0.92420 time= 0.08252\n",
      "Epoch: 0069 log_lik= 1.4127437 train_kl= 0.02726 train_loss= 1.44000 train_acc= 0.50221 val_roc= 0.91349 val_ap= 0.92376 time= 0.08301\n",
      "Epoch: 0070 log_lik= 1.4197116 train_kl= 0.02727 train_loss= 1.44698 train_acc= 0.50149 val_roc= 0.91350 val_ap= 0.92423 time= 0.08143\n",
      "Epoch: 0071 log_lik= 1.403249 train_kl= 0.02727 train_loss= 1.43052 train_acc= 0.50312 val_roc= 0.91388 val_ap= 0.92416 time= 0.08334\n",
      "Epoch: 0072 log_lik= 1.4169402 train_kl= 0.02726 train_loss= 1.44420 train_acc= 0.50226 val_roc= 0.91534 val_ap= 0.92472 time= 0.08262\n",
      "Epoch: 0073 log_lik= 1.4471772 train_kl= 0.02726 train_loss= 1.47444 train_acc= 0.50214 val_roc= 0.91600 val_ap= 0.92439 time= 0.08961\n",
      "Epoch: 0074 log_lik= 1.4743085 train_kl= 0.02725 train_loss= 1.50156 train_acc= 0.50250 val_roc= 0.91554 val_ap= 0.92364 time= 0.08498\n",
      "Epoch: 0075 log_lik= 1.4217606 train_kl= 0.02725 train_loss= 1.44901 train_acc= 0.50236 val_roc= 0.91493 val_ap= 0.92344 time= 0.08210\n",
      "Epoch: 0076 log_lik= 1.4678211 train_kl= 0.02724 train_loss= 1.49507 train_acc= 0.50120 val_roc= 0.91323 val_ap= 0.92283 time= 0.08101\n",
      "Epoch: 0077 log_lik= 1.4412818 train_kl= 0.02724 train_loss= 1.46853 train_acc= 0.50218 val_roc= 0.91141 val_ap= 0.92206 time= 0.08296\n",
      "Epoch: 0078 log_lik= 1.4321622 train_kl= 0.02725 train_loss= 1.45941 train_acc= 0.50324 val_roc= 0.91045 val_ap= 0.92164 time= 0.08395\n",
      "Epoch: 0079 log_lik= 1.3820449 train_kl= 0.02725 train_loss= 1.40930 train_acc= 0.50212 val_roc= 0.91047 val_ap= 0.92136 time= 0.08345\n",
      "Epoch: 0080 log_lik= 1.4102154 train_kl= 0.02726 train_loss= 1.43747 train_acc= 0.50249 val_roc= 0.91117 val_ap= 0.92156 time= 0.08401\n",
      "Epoch: 0081 log_lik= 1.4259901 train_kl= 0.02726 train_loss= 1.45325 train_acc= 0.50251 val_roc= 0.91227 val_ap= 0.92205 time= 0.08308\n",
      "Epoch: 0082 log_lik= 1.496161 train_kl= 0.02727 train_loss= 1.52343 train_acc= 0.50272 val_roc= 0.91227 val_ap= 0.92167 time= 0.08192\n",
      "Epoch: 0083 log_lik= 1.4437436 train_kl= 0.02727 train_loss= 1.47101 train_acc= 0.50228 val_roc= 0.91165 val_ap= 0.92065 time= 0.08300\n",
      "Epoch: 0084 log_lik= 1.407303 train_kl= 0.02727 train_loss= 1.43457 train_acc= 0.50251 val_roc= 0.91146 val_ap= 0.92045 time= 0.08397\n",
      "Epoch: 0085 log_lik= 1.437952 train_kl= 0.02727 train_loss= 1.46522 train_acc= 0.50315 val_roc= 0.91180 val_ap= 0.92089 time= 0.08252\n",
      "Epoch: 0086 log_lik= 1.4183443 train_kl= 0.02727 train_loss= 1.44561 train_acc= 0.50312 val_roc= 0.91236 val_ap= 0.92184 time= 0.08193\n",
      "Epoch: 0087 log_lik= 1.410587 train_kl= 0.02727 train_loss= 1.43785 train_acc= 0.50365 val_roc= 0.91311 val_ap= 0.92273 time= 0.08242\n",
      "Epoch: 0088 log_lik= 1.4465886 train_kl= 0.02726 train_loss= 1.47385 train_acc= 0.50282 val_roc= 0.91401 val_ap= 0.92361 time= 0.09098\n",
      "Epoch: 0089 log_lik= 1.4422209 train_kl= 0.02726 train_loss= 1.46949 train_acc= 0.50253 val_roc= 0.91456 val_ap= 0.92362 time= 0.08204\n",
      "Epoch: 0090 log_lik= 1.4286318 train_kl= 0.02727 train_loss= 1.45590 train_acc= 0.50241 val_roc= 0.91382 val_ap= 0.92317 time= 0.08199\n",
      "Epoch: 0091 log_lik= 1.4369451 train_kl= 0.02727 train_loss= 1.46421 train_acc= 0.50165 val_roc= 0.91336 val_ap= 0.92294 time= 0.08198\n",
      "Epoch: 0092 log_lik= 1.4283824 train_kl= 0.02727 train_loss= 1.45565 train_acc= 0.50248 val_roc= 0.91184 val_ap= 0.92217 time= 0.08403\n",
      "Epoch: 0093 log_lik= 1.4321984 train_kl= 0.02727 train_loss= 1.45947 train_acc= 0.50203 val_roc= 0.91139 val_ap= 0.92209 time= 0.08294\n",
      "Epoch: 0094 log_lik= 1.398079 train_kl= 0.02728 train_loss= 1.42536 train_acc= 0.50224 val_roc= 0.91252 val_ap= 0.92262 time= 0.08264\n",
      "Epoch: 0095 log_lik= 1.3973843 train_kl= 0.02728 train_loss= 1.42466 train_acc= 0.50216 val_roc= 0.91460 val_ap= 0.92345 time= 0.08463\n",
      "Epoch: 0096 log_lik= 1.4081557 train_kl= 0.02728 train_loss= 1.43544 train_acc= 0.50324 val_roc= 0.91612 val_ap= 0.92383 time= 0.08178\n",
      "Epoch: 0097 log_lik= 1.4087913 train_kl= 0.02728 train_loss= 1.43607 train_acc= 0.50284 val_roc= 0.91714 val_ap= 0.92464 time= 0.08500\n",
      "Epoch: 0098 log_lik= 1.4477383 train_kl= 0.02728 train_loss= 1.47502 train_acc= 0.50240 val_roc= 0.91717 val_ap= 0.92520 time= 0.08103\n",
      "Epoch: 0099 log_lik= 1.432963 train_kl= 0.02728 train_loss= 1.46024 train_acc= 0.50240 val_roc= 0.91638 val_ap= 0.92589 time= 0.08290\n",
      "Epoch: 0100 log_lik= 1.4319535 train_kl= 0.02728 train_loss= 1.45923 train_acc= 0.50154 val_roc= 0.91560 val_ap= 0.92583 time= 0.08909\n",
      "Epoch: 0101 log_lik= 1.4428335 train_kl= 0.02728 train_loss= 1.47011 train_acc= 0.50198 val_roc= 0.91399 val_ap= 0.92564 time= 0.08197\n",
      "Epoch: 0102 log_lik= 1.4054493 train_kl= 0.02727 train_loss= 1.43272 train_acc= 0.50190 val_roc= 0.91383 val_ap= 0.92594 time= 0.08296\n",
      "Epoch: 0103 log_lik= 1.4235098 train_kl= 0.02726 train_loss= 1.45077 train_acc= 0.50313 val_roc= 0.91415 val_ap= 0.92582 time= 0.08404\n",
      "Epoch: 0104 log_lik= 1.4032376 train_kl= 0.02726 train_loss= 1.43050 train_acc= 0.50295 val_roc= 0.91470 val_ap= 0.92593 time= 0.08100\n",
      "Epoch: 0105 log_lik= 1.4509761 train_kl= 0.02726 train_loss= 1.47824 train_acc= 0.50154 val_roc= 0.91454 val_ap= 0.92570 time= 0.08294\n",
      "Epoch: 0106 log_lik= 1.4062383 train_kl= 0.02726 train_loss= 1.43350 train_acc= 0.50217 val_roc= 0.91463 val_ap= 0.92611 time= 0.08312\n",
      "Epoch: 0107 log_lik= 1.4592366 train_kl= 0.02726 train_loss= 1.48650 train_acc= 0.50226 val_roc= 0.91324 val_ap= 0.92522 time= 0.08393\n",
      "Epoch: 0108 log_lik= 1.4488354 train_kl= 0.02726 train_loss= 1.47609 train_acc= 0.50287 val_roc= 0.91230 val_ap= 0.92485 time= 0.08513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0109 log_lik= 1.4104122 train_kl= 0.02726 train_loss= 1.43767 train_acc= 0.50277 val_roc= 0.91227 val_ap= 0.92474 time= 0.08195\n",
      "Epoch: 0110 log_lik= 1.4020631 train_kl= 0.02726 train_loss= 1.42932 train_acc= 0.50174 val_roc= 0.91288 val_ap= 0.92581 time= 0.08304\n",
      "Epoch: 0111 log_lik= 1.4376241 train_kl= 0.02726 train_loss= 1.46489 train_acc= 0.50220 val_roc= 0.91334 val_ap= 0.92629 time= 0.08199\n",
      "Epoch: 0112 log_lik= 1.4154751 train_kl= 0.02726 train_loss= 1.44274 train_acc= 0.50246 val_roc= 0.91346 val_ap= 0.92632 time= 0.08298\n",
      "Epoch: 0113 log_lik= 1.4272214 train_kl= 0.02727 train_loss= 1.45449 train_acc= 0.50268 val_roc= 0.91272 val_ap= 0.92556 time= 0.08296\n",
      "Epoch: 0114 log_lik= 1.413888 train_kl= 0.02727 train_loss= 1.44116 train_acc= 0.50296 val_roc= 0.91125 val_ap= 0.92401 time= 0.08203\n",
      "Epoch: 0115 log_lik= 1.4090276 train_kl= 0.02727 train_loss= 1.43630 train_acc= 0.50159 val_roc= 0.90893 val_ap= 0.92200 time= 0.08301\n",
      "Epoch: 0116 log_lik= 1.4208944 train_kl= 0.02727 train_loss= 1.44817 train_acc= 0.50194 val_roc= 0.90736 val_ap= 0.92055 time= 0.08303\n",
      "Epoch: 0117 log_lik= 1.4033927 train_kl= 0.02727 train_loss= 1.43067 train_acc= 0.50145 val_roc= 0.90755 val_ap= 0.92009 time= 0.08398\n",
      "Epoch: 0118 log_lik= 1.4038358 train_kl= 0.02728 train_loss= 1.43111 train_acc= 0.50200 val_roc= 0.90899 val_ap= 0.92083 time= 0.08494\n",
      "Epoch: 0119 log_lik= 1.4720649 train_kl= 0.02728 train_loss= 1.49934 train_acc= 0.50086 val_roc= 0.91064 val_ap= 0.92227 time= 0.08404\n",
      "Epoch: 0120 log_lik= 1.414564 train_kl= 0.02728 train_loss= 1.44185 train_acc= 0.50191 val_roc= 0.91217 val_ap= 0.92328 time= 0.08107\n",
      "Epoch: 0121 log_lik= 1.4246656 train_kl= 0.02728 train_loss= 1.45195 train_acc= 0.50290 val_roc= 0.91287 val_ap= 0.92351 time= 0.08313\n",
      "Epoch: 0122 log_lik= 1.414726 train_kl= 0.02728 train_loss= 1.44201 train_acc= 0.50292 val_roc= 0.91239 val_ap= 0.92267 time= 0.08179\n",
      "Epoch: 0123 log_lik= 1.4284358 train_kl= 0.02728 train_loss= 1.45572 train_acc= 0.50293 val_roc= 0.91216 val_ap= 0.92271 time= 0.08320\n",
      "Epoch: 0124 log_lik= 1.3929926 train_kl= 0.02729 train_loss= 1.42028 train_acc= 0.50268 val_roc= 0.91152 val_ap= 0.92268 time= 0.08984\n",
      "Epoch: 0125 log_lik= 1.430038 train_kl= 0.02729 train_loss= 1.45733 train_acc= 0.50239 val_roc= 0.91010 val_ap= 0.92128 time= 0.08200\n",
      "Epoch: 0126 log_lik= 1.4006205 train_kl= 0.02729 train_loss= 1.42791 train_acc= 0.50244 val_roc= 0.90961 val_ap= 0.92054 time= 0.08301\n",
      "Epoch: 0127 log_lik= 1.3843161 train_kl= 0.02730 train_loss= 1.41161 train_acc= 0.50290 val_roc= 0.90927 val_ap= 0.92035 time= 0.08964\n",
      "Epoch: 0128 log_lik= 1.445398 train_kl= 0.02730 train_loss= 1.47269 train_acc= 0.50226 val_roc= 0.90921 val_ap= 0.92064 time= 0.08465\n",
      "Epoch: 0129 log_lik= 1.4223347 train_kl= 0.02730 train_loss= 1.44963 train_acc= 0.50299 val_roc= 0.90982 val_ap= 0.92150 time= 0.08915\n",
      "Epoch: 0130 log_lik= 1.4404472 train_kl= 0.02730 train_loss= 1.46774 train_acc= 0.50323 val_roc= 0.91081 val_ap= 0.92246 time= 0.08861\n",
      "Epoch: 0131 log_lik= 1.4186807 train_kl= 0.02730 train_loss= 1.44598 train_acc= 0.50311 val_roc= 0.91125 val_ap= 0.92291 time= 0.09196\n",
      "Epoch: 0132 log_lik= 1.4248005 train_kl= 0.02730 train_loss= 1.45210 train_acc= 0.50136 val_roc= 0.91091 val_ap= 0.92284 time= 0.08416\n",
      "Epoch: 0133 log_lik= 1.4072516 train_kl= 0.02730 train_loss= 1.43455 train_acc= 0.50237 val_roc= 0.91005 val_ap= 0.92193 time= 0.08883\n",
      "Epoch: 0134 log_lik= 1.4182928 train_kl= 0.02730 train_loss= 1.44559 train_acc= 0.50248 val_roc= 0.90846 val_ap= 0.92055 time= 0.08093\n",
      "Epoch: 0135 log_lik= 1.4441682 train_kl= 0.02730 train_loss= 1.47146 train_acc= 0.50210 val_roc= 0.90708 val_ap= 0.91933 time= 0.08202\n",
      "Epoch: 0136 log_lik= 1.4079137 train_kl= 0.02729 train_loss= 1.43521 train_acc= 0.50161 val_roc= 0.90708 val_ap= 0.91956 time= 0.08305\n",
      "Epoch: 0137 log_lik= 1.3845087 train_kl= 0.02729 train_loss= 1.41180 train_acc= 0.50292 val_roc= 0.90679 val_ap= 0.91978 time= 0.09096\n",
      "Epoch: 0138 log_lik= 1.4318904 train_kl= 0.02728 train_loss= 1.45917 train_acc= 0.50314 val_roc= 0.90650 val_ap= 0.92049 time= 0.08397\n",
      "Epoch: 0139 log_lik= 1.4191895 train_kl= 0.02728 train_loss= 1.44647 train_acc= 0.50303 val_roc= 0.90637 val_ap= 0.92057 time= 0.08417\n",
      "Epoch: 0140 log_lik= 1.4214476 train_kl= 0.02728 train_loss= 1.44873 train_acc= 0.50157 val_roc= 0.90666 val_ap= 0.92067 time= 0.08186\n",
      "Epoch: 0141 log_lik= 1.3914347 train_kl= 0.02728 train_loss= 1.41872 train_acc= 0.50248 val_roc= 0.90642 val_ap= 0.92024 time= 0.08302\n",
      "Epoch: 0142 log_lik= 1.3857671 train_kl= 0.02728 train_loss= 1.41305 train_acc= 0.50202 val_roc= 0.90640 val_ap= 0.91981 time= 0.08200\n",
      "Epoch: 0143 log_lik= 1.4353766 train_kl= 0.02728 train_loss= 1.46265 train_acc= 0.50207 val_roc= 0.90535 val_ap= 0.91864 time= 0.08200\n",
      "Epoch: 0144 log_lik= 1.4367169 train_kl= 0.02728 train_loss= 1.46399 train_acc= 0.50134 val_roc= 0.90397 val_ap= 0.91776 time= 0.08499\n",
      "Epoch: 0145 log_lik= 1.4178288 train_kl= 0.02728 train_loss= 1.44511 train_acc= 0.50228 val_roc= 0.90294 val_ap= 0.91754 time= 0.08245\n",
      "Epoch: 0146 log_lik= 1.391357 train_kl= 0.02728 train_loss= 1.41864 train_acc= 0.50239 val_roc= 0.90174 val_ap= 0.91712 time= 0.08307\n",
      "Epoch: 0147 log_lik= 1.4269732 train_kl= 0.02728 train_loss= 1.45425 train_acc= 0.50260 val_roc= 0.90067 val_ap= 0.91598 time= 0.08348\n",
      "Epoch: 0148 log_lik= 1.4036174 train_kl= 0.02728 train_loss= 1.43090 train_acc= 0.50239 val_roc= 0.90074 val_ap= 0.91604 time= 0.08250\n",
      "Epoch: 0149 log_lik= 1.4135684 train_kl= 0.02729 train_loss= 1.44086 train_acc= 0.50099 val_roc= 0.90186 val_ap= 0.91715 time= 0.08400\n",
      "Epoch: 0150 log_lik= 1.3526418 train_kl= 0.02729 train_loss= 1.37994 train_acc= 0.50249 val_roc= 0.90374 val_ap= 0.91864 time= 0.08396\n",
      "Epoch: 0151 log_lik= 1.4012775 train_kl= 0.02729 train_loss= 1.42857 train_acc= 0.50217 val_roc= 0.90501 val_ap= 0.91925 time= 0.08218\n",
      "Epoch: 0152 log_lik= 1.3833402 train_kl= 0.02729 train_loss= 1.41063 train_acc= 0.50231 val_roc= 0.90616 val_ap= 0.91941 time= 0.08281\n",
      "Epoch: 0153 log_lik= 1.4108044 train_kl= 0.02729 train_loss= 1.43809 train_acc= 0.50295 val_roc= 0.90663 val_ap= 0.91925 time= 0.08184\n",
      "Epoch: 0154 log_lik= 1.4296966 train_kl= 0.02729 train_loss= 1.45699 train_acc= 0.50199 val_roc= 0.90627 val_ap= 0.91901 time= 0.08113\n",
      "Epoch: 0155 log_lik= 1.4204962 train_kl= 0.02729 train_loss= 1.44779 train_acc= 0.50316 val_roc= 0.90609 val_ap= 0.91897 time= 0.08257\n",
      "Epoch: 0156 log_lik= 1.4152124 train_kl= 0.02729 train_loss= 1.44250 train_acc= 0.50254 val_roc= 0.90632 val_ap= 0.91888 time= 0.08363\n",
      "Epoch: 0157 log_lik= 1.388816 train_kl= 0.02730 train_loss= 1.41611 train_acc= 0.50262 val_roc= 0.90682 val_ap= 0.91978 time= 0.08385\n",
      "Epoch: 0158 log_lik= 1.4254887 train_kl= 0.02730 train_loss= 1.45279 train_acc= 0.50279 val_roc= 0.90776 val_ap= 0.92089 time= 0.08303\n",
      "Epoch: 0159 log_lik= 1.4006666 train_kl= 0.02730 train_loss= 1.42797 train_acc= 0.50334 val_roc= 0.90811 val_ap= 0.92168 time= 0.08997\n",
      "Epoch: 0160 log_lik= 1.4232128 train_kl= 0.02731 train_loss= 1.45052 train_acc= 0.50228 val_roc= 0.90838 val_ap= 0.92250 time= 0.08238\n",
      "Epoch: 0161 log_lik= 1.4079299 train_kl= 0.02731 train_loss= 1.43524 train_acc= 0.50255 val_roc= 0.90820 val_ap= 0.92210 time= 0.08404\n",
      "Epoch: 0162 log_lik= 1.3935652 train_kl= 0.02731 train_loss= 1.42087 train_acc= 0.50322 val_roc= 0.90849 val_ap= 0.92168 time= 0.08497\n",
      "Epoch: 0163 log_lik= 1.4193268 train_kl= 0.02730 train_loss= 1.44663 train_acc= 0.50223 val_roc= 0.90883 val_ap= 0.92134 time= 0.08154\n",
      "Epoch: 0164 log_lik= 1.4252622 train_kl= 0.02730 train_loss= 1.45256 train_acc= 0.50298 val_roc= 0.90911 val_ap= 0.92130 time= 0.08295\n",
      "Epoch: 0165 log_lik= 1.4128017 train_kl= 0.02730 train_loss= 1.44010 train_acc= 0.50331 val_roc= 0.90860 val_ap= 0.92087 time= 0.08303\n",
      "Epoch: 0166 log_lik= 1.3964894 train_kl= 0.02730 train_loss= 1.42379 train_acc= 0.50267 val_roc= 0.90768 val_ap= 0.92058 time= 0.08310\n",
      "Epoch: 0167 log_lik= 1.3928269 train_kl= 0.02730 train_loss= 1.42012 train_acc= 0.50253 val_roc= 0.90718 val_ap= 0.92147 time= 0.08387\n",
      "Epoch: 0168 log_lik= 1.4117631 train_kl= 0.02729 train_loss= 1.43905 train_acc= 0.50335 val_roc= 0.90830 val_ap= 0.92335 time= 0.08849\n",
      "Epoch: 0169 log_lik= 1.4228334 train_kl= 0.02729 train_loss= 1.45012 train_acc= 0.50333 val_roc= 0.90919 val_ap= 0.92427 time= 0.08466\n",
      "Epoch: 0170 log_lik= 1.443639 train_kl= 0.02729 train_loss= 1.47093 train_acc= 0.50271 val_roc= 0.91115 val_ap= 0.92548 time= 0.08291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0171 log_lik= 1.3783937 train_kl= 0.02729 train_loss= 1.40569 train_acc= 0.50287 val_roc= 0.91155 val_ap= 0.92563 time= 0.08302\n",
      "Epoch: 0172 log_lik= 1.4243071 train_kl= 0.02730 train_loss= 1.45161 train_acc= 0.50250 val_roc= 0.91159 val_ap= 0.92564 time= 0.08300\n",
      "Epoch: 0173 log_lik= 1.4116455 train_kl= 0.02730 train_loss= 1.43895 train_acc= 0.50159 val_roc= 0.91061 val_ap= 0.92545 time= 0.08203\n",
      "Epoch: 0174 log_lik= 1.4255654 train_kl= 0.02730 train_loss= 1.45287 train_acc= 0.50168 val_roc= 0.90942 val_ap= 0.92465 time= 0.08300\n",
      "Epoch: 0175 log_lik= 1.4177856 train_kl= 0.02730 train_loss= 1.44509 train_acc= 0.50360 val_roc= 0.90766 val_ap= 0.92295 time= 0.08297\n",
      "Epoch: 0176 log_lik= 1.4017575 train_kl= 0.02730 train_loss= 1.42906 train_acc= 0.50304 val_roc= 0.90504 val_ap= 0.92025 time= 0.08208\n",
      "Epoch: 0177 log_lik= 1.3702575 train_kl= 0.02730 train_loss= 1.39756 train_acc= 0.50260 val_roc= 0.90406 val_ap= 0.91837 time= 0.08202\n",
      "Epoch: 0178 log_lik= 1.4267672 train_kl= 0.02730 train_loss= 1.45407 train_acc= 0.50166 val_roc= 0.90554 val_ap= 0.91844 time= 0.08300\n",
      "Epoch: 0179 log_lik= 1.4064105 train_kl= 0.02730 train_loss= 1.43371 train_acc= 0.50269 val_roc= 0.90591 val_ap= 0.91767 time= 0.08407\n",
      "Epoch: 0180 log_lik= 1.3979942 train_kl= 0.02730 train_loss= 1.42529 train_acc= 0.50061 val_roc= 0.90561 val_ap= 0.91698 time= 0.08492\n",
      "Epoch: 0181 log_lik= 1.4143777 train_kl= 0.02730 train_loss= 1.44167 train_acc= 0.50161 val_roc= 0.90528 val_ap= 0.91687 time= 0.08194\n",
      "Epoch: 0182 log_lik= 1.3736715 train_kl= 0.02729 train_loss= 1.40096 train_acc= 0.50296 val_roc= 0.90484 val_ap= 0.91676 time= 0.08105\n",
      "Epoch: 0183 log_lik= 1.3985604 train_kl= 0.02729 train_loss= 1.42585 train_acc= 0.50246 val_roc= 0.90357 val_ap= 0.91623 time= 0.08300\n",
      "Epoch: 0184 log_lik= 1.4222877 train_kl= 0.02729 train_loss= 1.44958 train_acc= 0.50299 val_roc= 0.90220 val_ap= 0.91533 time= 0.08103\n",
      "Epoch: 0185 log_lik= 1.4109944 train_kl= 0.02729 train_loss= 1.43829 train_acc= 0.50280 val_roc= 0.90116 val_ap= 0.91503 time= 0.08299\n",
      "Epoch: 0186 log_lik= 1.3906167 train_kl= 0.02730 train_loss= 1.41791 train_acc= 0.50141 val_roc= 0.90055 val_ap= 0.91403 time= 0.08194\n",
      "Epoch: 0187 log_lik= 1.3914062 train_kl= 0.02730 train_loss= 1.41871 train_acc= 0.50250 val_roc= 0.90156 val_ap= 0.91414 time= 0.08405\n",
      "Epoch: 0188 log_lik= 1.389706 train_kl= 0.02731 train_loss= 1.41701 train_acc= 0.50246 val_roc= 0.90280 val_ap= 0.91375 time= 0.08204\n",
      "Epoch: 0189 log_lik= 1.4334042 train_kl= 0.02731 train_loss= 1.46071 train_acc= 0.50247 val_roc= 0.90405 val_ap= 0.91378 time= 0.08193\n",
      "Epoch: 0190 log_lik= 1.4138498 train_kl= 0.02731 train_loss= 1.44116 train_acc= 0.50159 val_roc= 0.90445 val_ap= 0.91408 time= 0.08215\n",
      "Epoch: 0191 log_lik= 1.42945 train_kl= 0.02731 train_loss= 1.45676 train_acc= 0.50140 val_roc= 0.90351 val_ap= 0.91485 time= 0.08201\n",
      "Epoch: 0192 log_lik= 1.379628 train_kl= 0.02730 train_loss= 1.40693 train_acc= 0.50223 val_roc= 0.90165 val_ap= 0.91520 time= 0.08397\n",
      "Epoch: 0193 log_lik= 1.3786201 train_kl= 0.02730 train_loss= 1.40592 train_acc= 0.50232 val_roc= 0.90074 val_ap= 0.91573 time= 0.08299\n",
      "Epoch: 0194 log_lik= 1.3929775 train_kl= 0.02730 train_loss= 1.42027 train_acc= 0.50207 val_roc= 0.90104 val_ap= 0.91688 time= 0.08301\n",
      "Epoch: 0195 log_lik= 1.4059368 train_kl= 0.02729 train_loss= 1.43323 train_acc= 0.50180 val_roc= 0.90259 val_ap= 0.91811 time= 0.08305\n",
      "Epoch: 0196 log_lik= 1.3853037 train_kl= 0.02729 train_loss= 1.41259 train_acc= 0.50207 val_roc= 0.90406 val_ap= 0.91891 time= 0.08203\n",
      "Epoch: 0197 log_lik= 1.339462 train_kl= 0.02729 train_loss= 1.36675 train_acc= 0.50241 val_roc= 0.90493 val_ap= 0.91954 time= 0.08197\n",
      "Epoch: 0198 log_lik= 1.3752635 train_kl= 0.02728 train_loss= 1.40255 train_acc= 0.50178 val_roc= 0.90504 val_ap= 0.91975 time= 0.08300\n",
      "Epoch: 0199 log_lik= 1.402976 train_kl= 0.02728 train_loss= 1.43025 train_acc= 0.50226 val_roc= 0.90356 val_ap= 0.91924 time= 0.08202\n",
      "Epoch: 0200 log_lik= 1.3863286 train_kl= 0.02727 train_loss= 1.41360 train_acc= 0.50142 val_roc= 0.90286 val_ap= 0.91879 time= 0.08300\n",
      "Optimization Finished!\n",
      "Test ROC score: 0.8947031098660925\n",
      "Test AP score: 0.9101186529998867\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CMGAE\n",
    "%run train_debug.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fc64068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\jupyter\\gae\\gae\\train_debug.py:103: The name tf.sparse_placeholder is deprecated. Please use tf.compat.v1.sparse_placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\jupyter\\gae\\gae\\train_debug.py:106: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\gae-0.0.1-py3.7.egg\\gae\\model.py:31: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\gae-0.0.1-py3.7.egg\\gae\\initializations.py:9: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\gae-0.0.1-py3.7.egg\\gae\\layers.py:29: The name tf.sparse_retain is deprecated. Please use tf.sparse.retain instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\tensorflow\\python\\ops\\sparse_ops.py:1719: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\gae-0.0.1-py3.7.egg\\gae\\layers.py:80: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\gae-0.0.1-py3.7.egg\\gae\\optimizer.py:98: calling weighted_cross_entropy_with_logits (from tensorflow.python.ops.nn_impl) with targets is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "targets is deprecated, use labels instead\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\gae-0.0.1-py3.7.egg\\gae\\optimizer.py:100: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "Epoch: 0001 train_loss= 1.84251 train_acc= 0.49515 val_roc= 0.71872 val_ap= 0.74799 time= 1.99383\n",
      "Epoch: 0002 train_loss= 1.73030 train_acc= 0.48646 val_roc= 0.70685 val_ap= 0.72391 time= 0.08657\n",
      "Epoch: 0003 train_loss= 1.76957 train_acc= 0.48550 val_roc= 0.72936 val_ap= 0.73822 time= 0.08816\n",
      "Epoch: 0004 train_loss= 1.75605 train_acc= 0.48046 val_roc= 0.77611 val_ap= 0.77497 time= 0.08373\n",
      "Epoch: 0005 train_loss= 1.75223 train_acc= 0.48345 val_roc= 0.80274 val_ap= 0.80272 time= 0.08164\n",
      "Epoch: 0006 train_loss= 1.66409 train_acc= 0.48609 val_roc= 0.80678 val_ap= 0.80785 time= 0.08166\n",
      "Epoch: 0007 train_loss= 1.68560 train_acc= 0.48601 val_roc= 0.80279 val_ap= 0.80208 time= 0.08267\n",
      "Epoch: 0008 train_loss= 1.63648 train_acc= 0.48872 val_roc= 0.80287 val_ap= 0.80864 time= 0.08168\n",
      "Epoch: 0009 train_loss= 1.63062 train_acc= 0.49258 val_roc= 0.80052 val_ap= 0.80338 time= 0.08217\n",
      "Epoch: 0010 train_loss= 1.62584 train_acc= 0.49697 val_roc= 0.81071 val_ap= 0.81708 time= 0.08264\n",
      "Epoch: 0011 train_loss= 1.59139 train_acc= 0.49746 val_roc= 0.82481 val_ap= 0.83376 time= 0.08164\n",
      "Epoch: 0012 train_loss= 1.62231 train_acc= 0.49340 val_roc= 0.83514 val_ap= 0.84269 time= 0.08164\n",
      "Epoch: 0013 train_loss= 1.62538 train_acc= 0.49572 val_roc= 0.84500 val_ap= 0.85340 time= 0.08264\n",
      "Epoch: 0014 train_loss= 1.57015 train_acc= 0.49844 val_roc= 0.85736 val_ap= 0.86857 time= 0.08165\n",
      "Epoch: 0015 train_loss= 1.53406 train_acc= 0.49936 val_roc= 0.86559 val_ap= 0.87307 time= 0.08064\n",
      "Epoch: 0016 train_loss= 1.55029 train_acc= 0.49885 val_roc= 0.87473 val_ap= 0.87913 time= 0.08179\n",
      "Epoch: 0017 train_loss= 1.56677 train_acc= 0.49663 val_roc= 0.88368 val_ap= 0.88595 time= 0.08294\n",
      "Epoch: 0018 train_loss= 1.53076 train_acc= 0.49785 val_roc= 0.88892 val_ap= 0.88991 time= 0.08102\n",
      "Epoch: 0019 train_loss= 1.57302 train_acc= 0.49876 val_roc= 0.89014 val_ap= 0.88996 time= 0.08503\n",
      "Epoch: 0020 train_loss= 1.53925 train_acc= 0.49813 val_roc= 0.88929 val_ap= 0.88950 time= 0.08297\n",
      "Epoch: 0021 train_loss= 1.49626 train_acc= 0.50179 val_roc= 0.88696 val_ap= 0.88795 time= 0.08299\n",
      "Epoch: 0022 train_loss= 1.50344 train_acc= 0.50155 val_roc= 0.88943 val_ap= 0.89173 time= 0.08405\n",
      "Epoch: 0023 train_loss= 1.50896 train_acc= 0.50149 val_roc= 0.89296 val_ap= 0.89585 time= 0.08006\n",
      "Epoch: 0024 train_loss= 1.52456 train_acc= 0.50051 val_roc= 0.89641 val_ap= 0.90044 time= 0.08096\n",
      "Epoch: 0025 train_loss= 1.50629 train_acc= 0.49894 val_roc= 0.89841 val_ap= 0.90382 time= 0.08295\n",
      "Epoch: 0026 train_loss= 1.45016 train_acc= 0.50049 val_roc= 0.89813 val_ap= 0.90408 time= 0.08209\n",
      "Epoch: 0027 train_loss= 1.51680 train_acc= 0.50025 val_roc= 0.89633 val_ap= 0.90217 time= 0.08196\n",
      "Epoch: 0028 train_loss= 1.49261 train_acc= 0.50070 val_roc= 0.89582 val_ap= 0.90233 time= 0.08201\n",
      "Epoch: 0029 train_loss= 1.50113 train_acc= 0.50152 val_roc= 0.89634 val_ap= 0.90352 time= 0.08103\n",
      "Epoch: 0030 train_loss= 1.53718 train_acc= 0.50011 val_roc= 0.89698 val_ap= 0.90400 time= 0.08196\n",
      "Epoch: 0031 train_loss= 1.47583 train_acc= 0.50112 val_roc= 0.89806 val_ap= 0.90431 time= 0.08201\n",
      "Epoch: 0032 train_loss= 1.50052 train_acc= 0.50219 val_roc= 0.89851 val_ap= 0.90403 time= 0.08205\n",
      "Epoch: 0033 train_loss= 1.48941 train_acc= 0.50193 val_roc= 0.89938 val_ap= 0.90454 time= 0.08298\n",
      "Epoch: 0034 train_loss= 1.52554 train_acc= 0.50189 val_roc= 0.89954 val_ap= 0.90454 time= 0.08505\n",
      "Epoch: 0035 train_loss= 1.50258 train_acc= 0.50143 val_roc= 0.89902 val_ap= 0.90338 time= 0.08496\n",
      "Epoch: 0036 train_loss= 1.52311 train_acc= 0.50134 val_roc= 0.90019 val_ap= 0.90379 time= 0.08352\n",
      "Epoch: 0037 train_loss= 1.48379 train_acc= 0.50144 val_roc= 0.90188 val_ap= 0.90547 time= 0.08247\n",
      "Epoch: 0038 train_loss= 1.49760 train_acc= 0.50124 val_roc= 0.90296 val_ap= 0.90646 time= 0.08201\n",
      "Epoch: 0039 train_loss= 1.45443 train_acc= 0.50129 val_roc= 0.90374 val_ap= 0.90663 time= 0.08200\n",
      "Epoch: 0040 train_loss= 1.44780 train_acc= 0.50273 val_roc= 0.90425 val_ap= 0.90680 time= 0.08096\n",
      "Epoch: 0041 train_loss= 1.45640 train_acc= 0.50218 val_roc= 0.90525 val_ap= 0.90777 time= 0.08313\n",
      "Epoch: 0042 train_loss= 1.44433 train_acc= 0.50154 val_roc= 0.90577 val_ap= 0.90840 time= 0.08194\n",
      "Epoch: 0043 train_loss= 1.48587 train_acc= 0.50195 val_roc= 0.90509 val_ap= 0.90778 time= 0.08404\n",
      "Epoch: 0044 train_loss= 1.50846 train_acc= 0.50036 val_roc= 0.90395 val_ap= 0.90685 time= 0.08295\n",
      "Epoch: 0045 train_loss= 1.50854 train_acc= 0.50115 val_roc= 0.90484 val_ap= 0.90679 time= 0.08301\n",
      "Epoch: 0046 train_loss= 1.49754 train_acc= 0.50164 val_roc= 0.90513 val_ap= 0.90634 time= 0.08303\n",
      "Epoch: 0047 train_loss= 1.44198 train_acc= 0.50137 val_roc= 0.90587 val_ap= 0.90653 time= 0.08403\n",
      "Epoch: 0048 train_loss= 1.48038 train_acc= 0.50119 val_roc= 0.90609 val_ap= 0.90713 time= 0.08491\n",
      "Epoch: 0049 train_loss= 1.51692 train_acc= 0.50085 val_roc= 0.90595 val_ap= 0.90803 time= 0.08307\n",
      "Epoch: 0050 train_loss= 1.51655 train_acc= 0.50183 val_roc= 0.90600 val_ap= 0.90946 time= 0.08190\n",
      "Epoch: 0051 train_loss= 1.46472 train_acc= 0.50177 val_roc= 0.90578 val_ap= 0.90946 time= 0.08209\n",
      "Epoch: 0052 train_loss= 1.46930 train_acc= 0.50278 val_roc= 0.90593 val_ap= 0.90943 time= 0.08499\n",
      "Epoch: 0053 train_loss= 1.45948 train_acc= 0.50231 val_roc= 0.90617 val_ap= 0.90876 time= 0.08400\n",
      "Epoch: 0054 train_loss= 1.52071 train_acc= 0.50150 val_roc= 0.90752 val_ap= 0.90948 time= 0.08297\n",
      "Epoch: 0055 train_loss= 1.47932 train_acc= 0.50207 val_roc= 0.90792 val_ap= 0.91027 time= 0.08199\n",
      "Epoch: 0056 train_loss= 1.47958 train_acc= 0.50313 val_roc= 0.90726 val_ap= 0.90978 time= 0.08201\n",
      "Epoch: 0057 train_loss= 1.46856 train_acc= 0.50144 val_roc= 0.90668 val_ap= 0.91029 time= 0.08301\n",
      "Epoch: 0058 train_loss= 1.46577 train_acc= 0.50176 val_roc= 0.90567 val_ap= 0.91051 time= 0.08905\n",
      "Epoch: 0059 train_loss= 1.51361 train_acc= 0.50202 val_roc= 0.90548 val_ap= 0.91108 time= 0.08305\n",
      "Epoch: 0060 train_loss= 1.46949 train_acc= 0.50173 val_roc= 0.90658 val_ap= 0.91150 time= 0.08395\n",
      "Epoch: 0061 train_loss= 1.43196 train_acc= 0.50190 val_roc= 0.90718 val_ap= 0.91137 time= 0.08298\n",
      "Epoch: 0062 train_loss= 1.50149 train_acc= 0.50214 val_roc= 0.90668 val_ap= 0.91060 time= 0.08100\n",
      "Epoch: 0063 train_loss= 1.44789 train_acc= 0.50262 val_roc= 0.90484 val_ap= 0.90817 time= 0.08307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0064 train_loss= 1.47099 train_acc= 0.50241 val_roc= 0.90425 val_ap= 0.90875 time= 0.08694\n",
      "Epoch: 0065 train_loss= 1.47153 train_acc= 0.50250 val_roc= 0.90416 val_ap= 0.91045 time= 0.08204\n",
      "Epoch: 0066 train_loss= 1.44017 train_acc= 0.50297 val_roc= 0.90419 val_ap= 0.91205 time= 0.08198\n",
      "Epoch: 0067 train_loss= 1.49879 train_acc= 0.50286 val_roc= 0.90507 val_ap= 0.91358 time= 0.08300\n",
      "Epoch: 0068 train_loss= 1.50702 train_acc= 0.50228 val_roc= 0.90571 val_ap= 0.91425 time= 0.08307\n",
      "Epoch: 0069 train_loss= 1.51198 train_acc= 0.50136 val_roc= 0.90658 val_ap= 0.91394 time= 0.08233\n",
      "Epoch: 0070 train_loss= 1.48383 train_acc= 0.50175 val_roc= 0.90685 val_ap= 0.91442 time= 0.08395\n",
      "Epoch: 0071 train_loss= 1.44650 train_acc= 0.50326 val_roc= 0.90617 val_ap= 0.91260 time= 0.08167\n",
      "Epoch: 0072 train_loss= 1.44628 train_acc= 0.50269 val_roc= 0.90478 val_ap= 0.91100 time= 0.08206\n",
      "Epoch: 0073 train_loss= 1.45029 train_acc= 0.50236 val_roc= 0.90552 val_ap= 0.91205 time= 0.08495\n",
      "Epoch: 0074 train_loss= 1.43558 train_acc= 0.50189 val_roc= 0.90766 val_ap= 0.91444 time= 0.08300\n",
      "Epoch: 0075 train_loss= 1.46630 train_acc= 0.50258 val_roc= 0.90831 val_ap= 0.91598 time= 0.08197\n",
      "Epoch: 0076 train_loss= 1.41930 train_acc= 0.50237 val_roc= 0.90807 val_ap= 0.91608 time= 0.07895\n",
      "Epoch: 0077 train_loss= 1.48303 train_acc= 0.50108 val_roc= 0.90743 val_ap= 0.91532 time= 0.08217\n",
      "Epoch: 0078 train_loss= 1.42600 train_acc= 0.50168 val_roc= 0.90705 val_ap= 0.91425 time= 0.08291\n",
      "Epoch: 0079 train_loss= 1.44385 train_acc= 0.50247 val_roc= 0.90509 val_ap= 0.91126 time= 0.08296\n",
      "Epoch: 0080 train_loss= 1.45230 train_acc= 0.50327 val_roc= 0.90270 val_ap= 0.90759 time= 0.08204\n",
      "Epoch: 0081 train_loss= 1.44916 train_acc= 0.50085 val_roc= 0.90196 val_ap= 0.90637 time= 0.08197\n",
      "Epoch: 0082 train_loss= 1.42839 train_acc= 0.50162 val_roc= 0.90273 val_ap= 0.90718 time= 0.08298\n",
      "Epoch: 0083 train_loss= 1.46929 train_acc= 0.50230 val_roc= 0.90347 val_ap= 0.90824 time= 0.08312\n",
      "Epoch: 0084 train_loss= 1.50425 train_acc= 0.50211 val_roc= 0.90502 val_ap= 0.91024 time= 0.08195\n",
      "Epoch: 0085 train_loss= 1.48554 train_acc= 0.50316 val_roc= 0.90575 val_ap= 0.91218 time= 0.08302\n",
      "Epoch: 0086 train_loss= 1.44823 train_acc= 0.50257 val_roc= 0.90624 val_ap= 0.91312 time= 0.08294\n",
      "Epoch: 0087 train_loss= 1.47483 train_acc= 0.50225 val_roc= 0.90610 val_ap= 0.91374 time= 0.08214\n",
      "Epoch: 0088 train_loss= 1.46226 train_acc= 0.50182 val_roc= 0.90523 val_ap= 0.91336 time= 0.08293\n",
      "Epoch: 0089 train_loss= 1.47325 train_acc= 0.50292 val_roc= 0.90396 val_ap= 0.91208 time= 0.08001\n",
      "Epoch: 0090 train_loss= 1.48556 train_acc= 0.50199 val_roc= 0.90290 val_ap= 0.91093 time= 0.08103\n",
      "Epoch: 0091 train_loss= 1.44584 train_acc= 0.50304 val_roc= 0.90214 val_ap= 0.90942 time= 0.08996\n",
      "Epoch: 0092 train_loss= 1.45699 train_acc= 0.50211 val_roc= 0.90277 val_ap= 0.90974 time= 0.08096\n",
      "Epoch: 0093 train_loss= 1.46407 train_acc= 0.50199 val_roc= 0.90507 val_ap= 0.91164 time= 0.09000\n",
      "Epoch: 0094 train_loss= 1.46305 train_acc= 0.50213 val_roc= 0.90640 val_ap= 0.91261 time= 0.08313\n",
      "Epoch: 0095 train_loss= 1.45323 train_acc= 0.50110 val_roc= 0.90700 val_ap= 0.91323 time= 0.08089\n",
      "Epoch: 0096 train_loss= 1.45318 train_acc= 0.50083 val_roc= 0.90678 val_ap= 0.91349 time= 0.08303\n",
      "Epoch: 0097 train_loss= 1.45983 train_acc= 0.50144 val_roc= 0.90736 val_ap= 0.91437 time= 0.08307\n",
      "Epoch: 0098 train_loss= 1.44696 train_acc= 0.50167 val_roc= 0.90648 val_ap= 0.91370 time= 0.08295\n",
      "Epoch: 0099 train_loss= 1.44813 train_acc= 0.50212 val_roc= 0.90503 val_ap= 0.91229 time= 0.08197\n",
      "Epoch: 0100 train_loss= 1.48411 train_acc= 0.50146 val_roc= 0.90389 val_ap= 0.91030 time= 0.08299\n",
      "Epoch: 0101 train_loss= 1.45083 train_acc= 0.50213 val_roc= 0.90400 val_ap= 0.90970 time= 0.08406\n",
      "Epoch: 0102 train_loss= 1.41974 train_acc= 0.50237 val_roc= 0.90400 val_ap= 0.90844 time= 0.08294\n",
      "Epoch: 0103 train_loss= 1.38800 train_acc= 0.50238 val_roc= 0.90309 val_ap= 0.90718 time= 0.08603\n",
      "Epoch: 0104 train_loss= 1.42690 train_acc= 0.50266 val_roc= 0.90318 val_ap= 0.90782 time= 0.08198\n",
      "Epoch: 0105 train_loss= 1.45744 train_acc= 0.50210 val_roc= 0.90436 val_ap= 0.90987 time= 0.08923\n",
      "Epoch: 0106 train_loss= 1.47442 train_acc= 0.50231 val_roc= 0.90640 val_ap= 0.91228 time= 0.08378\n",
      "Epoch: 0107 train_loss= 1.39996 train_acc= 0.50270 val_roc= 0.90726 val_ap= 0.91324 time= 0.08401\n",
      "Epoch: 0108 train_loss= 1.49236 train_acc= 0.50303 val_roc= 0.90743 val_ap= 0.91364 time= 0.08203\n",
      "Epoch: 0109 train_loss= 1.44768 train_acc= 0.50203 val_roc= 0.90556 val_ap= 0.91207 time= 0.08550\n",
      "Epoch: 0110 train_loss= 1.42035 train_acc= 0.50335 val_roc= 0.90338 val_ap= 0.90979 time= 0.08295\n",
      "Epoch: 0111 train_loss= 1.44196 train_acc= 0.50269 val_roc= 0.90243 val_ap= 0.90856 time= 0.08396\n",
      "Epoch: 0112 train_loss= 1.44677 train_acc= 0.50239 val_roc= 0.90205 val_ap= 0.90736 time= 0.08292\n",
      "Epoch: 0113 train_loss= 1.44906 train_acc= 0.50268 val_roc= 0.90293 val_ap= 0.90770 time= 0.09113\n",
      "Epoch: 0114 train_loss= 1.48566 train_acc= 0.50175 val_roc= 0.90393 val_ap= 0.90877 time= 0.08296\n",
      "Epoch: 0115 train_loss= 1.42825 train_acc= 0.50225 val_roc= 0.90558 val_ap= 0.91007 time= 0.08096\n",
      "Epoch: 0116 train_loss= 1.42946 train_acc= 0.50322 val_roc= 0.90616 val_ap= 0.91129 time= 0.08605\n",
      "Epoch: 0117 train_loss= 1.46552 train_acc= 0.50349 val_roc= 0.90658 val_ap= 0.91168 time= 0.08295\n",
      "Epoch: 0118 train_loss= 1.41544 train_acc= 0.50263 val_roc= 0.90689 val_ap= 0.91189 time= 0.08204\n",
      "Epoch: 0119 train_loss= 1.45338 train_acc= 0.50213 val_roc= 0.90701 val_ap= 0.91189 time= 0.08299\n",
      "Epoch: 0120 train_loss= 1.45907 train_acc= 0.50231 val_roc= 0.90698 val_ap= 0.91198 time= 0.08460\n",
      "Epoch: 0121 train_loss= 1.41711 train_acc= 0.50275 val_roc= 0.90494 val_ap= 0.91026 time= 0.08064\n",
      "Epoch: 0122 train_loss= 1.39262 train_acc= 0.50340 val_roc= 0.90353 val_ap= 0.90950 time= 0.08376\n",
      "Epoch: 0123 train_loss= 1.42855 train_acc= 0.50247 val_roc= 0.90267 val_ap= 0.90996 time= 0.08298\n",
      "Epoch: 0124 train_loss= 1.44969 train_acc= 0.50174 val_roc= 0.90351 val_ap= 0.91098 time= 0.08405\n",
      "Epoch: 0125 train_loss= 1.45721 train_acc= 0.50212 val_roc= 0.90476 val_ap= 0.91249 time= 0.08201\n",
      "Epoch: 0126 train_loss= 1.42126 train_acc= 0.50345 val_roc= 0.90600 val_ap= 0.91353 time= 0.08197\n",
      "Epoch: 0127 train_loss= 1.42555 train_acc= 0.50213 val_roc= 0.90668 val_ap= 0.91454 time= 0.08401\n",
      "Epoch: 0128 train_loss= 1.47173 train_acc= 0.50237 val_roc= 0.90786 val_ap= 0.91544 time= 0.08108\n",
      "Epoch: 0129 train_loss= 1.46837 train_acc= 0.50238 val_roc= 0.90885 val_ap= 0.91634 time= 0.08389\n",
      "Epoch: 0130 train_loss= 1.46730 train_acc= 0.50242 val_roc= 0.90895 val_ap= 0.91659 time= 0.08407\n",
      "Epoch: 0131 train_loss= 1.46467 train_acc= 0.50339 val_roc= 0.90746 val_ap= 0.91536 time= 0.08196\n",
      "Epoch: 0132 train_loss= 1.40953 train_acc= 0.50314 val_roc= 0.90685 val_ap= 0.91510 time= 0.08814\n",
      "Epoch: 0133 train_loss= 1.42364 train_acc= 0.50247 val_roc= 0.90720 val_ap= 0.91590 time= 0.08492\n",
      "Epoch: 0134 train_loss= 1.45377 train_acc= 0.50243 val_roc= 0.90864 val_ap= 0.91813 time= 0.08224\n",
      "Epoch: 0135 train_loss= 1.43028 train_acc= 0.50326 val_roc= 0.90885 val_ap= 0.91932 time= 0.08277\n",
      "Epoch: 0136 train_loss= 1.43631 train_acc= 0.50308 val_roc= 0.90889 val_ap= 0.91963 time= 0.08403\n",
      "Epoch: 0137 train_loss= 1.42740 train_acc= 0.50338 val_roc= 0.90883 val_ap= 0.91993 time= 0.08997\n",
      "Epoch: 0138 train_loss= 1.44243 train_acc= 0.50323 val_roc= 0.90912 val_ap= 0.92025 time= 0.08201\n",
      "Epoch: 0139 train_loss= 1.44362 train_acc= 0.50308 val_roc= 0.90922 val_ap= 0.92040 time= 0.08300\n",
      "Epoch: 0140 train_loss= 1.42672 train_acc= 0.50275 val_roc= 0.90947 val_ap= 0.92026 time= 0.08401\n",
      "Epoch: 0141 train_loss= 1.45562 train_acc= 0.50236 val_roc= 0.90841 val_ap= 0.91947 time= 0.08502\n",
      "Epoch: 0142 train_loss= 1.42233 train_acc= 0.50305 val_roc= 0.90740 val_ap= 0.91836 time= 0.08299\n",
      "Epoch: 0143 train_loss= 1.47982 train_acc= 0.50238 val_roc= 0.90663 val_ap= 0.91803 time= 0.08200\n",
      "Epoch: 0144 train_loss= 1.41367 train_acc= 0.50230 val_roc= 0.90685 val_ap= 0.91853 time= 0.08997\n",
      "Epoch: 0145 train_loss= 1.43639 train_acc= 0.50279 val_roc= 0.90694 val_ap= 0.91845 time= 0.08348\n",
      "Epoch: 0146 train_loss= 1.44550 train_acc= 0.50201 val_roc= 0.90762 val_ap= 0.91876 time= 0.08500\n",
      "Epoch: 0147 train_loss= 1.48098 train_acc= 0.50335 val_roc= 0.90812 val_ap= 0.91888 time= 0.08306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0148 train_loss= 1.42541 train_acc= 0.50261 val_roc= 0.90908 val_ap= 0.91935 time= 0.08364\n",
      "Epoch: 0149 train_loss= 1.39235 train_acc= 0.50114 val_roc= 0.90986 val_ap= 0.91946 time= 0.08322\n",
      "Epoch: 0150 train_loss= 1.45091 train_acc= 0.50248 val_roc= 0.91093 val_ap= 0.92016 time= 0.08387\n",
      "Epoch: 0151 train_loss= 1.49091 train_acc= 0.50212 val_roc= 0.91088 val_ap= 0.91994 time= 0.08166\n",
      "Epoch: 0152 train_loss= 1.44423 train_acc= 0.50191 val_roc= 0.91088 val_ap= 0.91957 time= 0.08159\n",
      "Epoch: 0153 train_loss= 1.44707 train_acc= 0.50206 val_roc= 0.91103 val_ap= 0.91928 time= 0.08398\n",
      "Epoch: 0154 train_loss= 1.42929 train_acc= 0.50224 val_roc= 0.91182 val_ap= 0.92031 time= 0.08199\n",
      "Epoch: 0155 train_loss= 1.38985 train_acc= 0.50288 val_roc= 0.91240 val_ap= 0.92095 time= 0.08199\n",
      "Epoch: 0156 train_loss= 1.41816 train_acc= 0.50215 val_roc= 0.91207 val_ap= 0.92052 time= 0.09098\n",
      "Epoch: 0157 train_loss= 1.43871 train_acc= 0.50214 val_roc= 0.91184 val_ap= 0.92049 time= 0.08499\n",
      "Epoch: 0158 train_loss= 1.43792 train_acc= 0.50184 val_roc= 0.91152 val_ap= 0.92070 time= 0.08306\n",
      "Epoch: 0159 train_loss= 1.46191 train_acc= 0.50194 val_roc= 0.91041 val_ap= 0.92037 time= 0.08198\n",
      "Epoch: 0160 train_loss= 1.44795 train_acc= 0.50181 val_roc= 0.91016 val_ap= 0.92053 time= 0.08391\n",
      "Epoch: 0161 train_loss= 1.43203 train_acc= 0.50232 val_roc= 0.90999 val_ap= 0.92096 time= 0.08303\n",
      "Epoch: 0162 train_loss= 1.42245 train_acc= 0.50318 val_roc= 0.90942 val_ap= 0.92019 time= 0.08200\n",
      "Epoch: 0163 train_loss= 1.44935 train_acc= 0.50233 val_roc= 0.90984 val_ap= 0.92003 time= 0.08210\n",
      "Epoch: 0164 train_loss= 1.42353 train_acc= 0.50294 val_roc= 0.90976 val_ap= 0.91954 time= 0.08305\n",
      "Epoch: 0165 train_loss= 1.44420 train_acc= 0.50272 val_roc= 0.90982 val_ap= 0.91896 time= 0.08187\n",
      "Epoch: 0166 train_loss= 1.44197 train_acc= 0.50271 val_roc= 0.90935 val_ap= 0.91843 time= 0.08200\n",
      "Epoch: 0167 train_loss= 1.44649 train_acc= 0.50251 val_roc= 0.90929 val_ap= 0.91853 time= 0.08207\n",
      "Epoch: 0168 train_loss= 1.42464 train_acc= 0.50274 val_roc= 0.90947 val_ap= 0.91896 time= 0.08301\n",
      "Epoch: 0169 train_loss= 1.45647 train_acc= 0.50278 val_roc= 0.90992 val_ap= 0.91955 time= 0.08298\n",
      "Epoch: 0170 train_loss= 1.40921 train_acc= 0.50285 val_roc= 0.91049 val_ap= 0.92041 time= 0.08210\n",
      "Epoch: 0171 train_loss= 1.42080 train_acc= 0.50276 val_roc= 0.91031 val_ap= 0.92062 time= 0.08288\n",
      "Epoch: 0172 train_loss= 1.41000 train_acc= 0.50287 val_roc= 0.91062 val_ap= 0.92129 time= 0.08303\n",
      "Epoch: 0173 train_loss= 1.42132 train_acc= 0.50280 val_roc= 0.90996 val_ap= 0.92091 time= 0.08501\n",
      "Epoch: 0174 train_loss= 1.43123 train_acc= 0.50238 val_roc= 0.90999 val_ap= 0.92078 time= 0.08300\n",
      "Epoch: 0175 train_loss= 1.43534 train_acc= 0.50272 val_roc= 0.90950 val_ap= 0.92048 time= 0.08396\n",
      "Epoch: 0176 train_loss= 1.43024 train_acc= 0.50287 val_roc= 0.90947 val_ap= 0.92056 time= 0.08299\n",
      "Epoch: 0177 train_loss= 1.44033 train_acc= 0.50289 val_roc= 0.90843 val_ap= 0.91920 time= 0.08207\n",
      "Epoch: 0178 train_loss= 1.43516 train_acc= 0.50222 val_roc= 0.90867 val_ap= 0.91915 time= 0.08293\n",
      "Epoch: 0179 train_loss= 1.42383 train_acc= 0.50276 val_roc= 0.90941 val_ap= 0.91950 time= 0.08209\n",
      "Epoch: 0180 train_loss= 1.44442 train_acc= 0.50266 val_roc= 0.91012 val_ap= 0.92008 time= 0.08296\n",
      "Epoch: 0181 train_loss= 1.46105 train_acc= 0.50293 val_roc= 0.90986 val_ap= 0.91960 time= 0.08398\n",
      "Epoch: 0182 train_loss= 1.46543 train_acc= 0.50369 val_roc= 0.90971 val_ap= 0.91911 time= 0.08106\n",
      "Epoch: 0183 train_loss= 1.41708 train_acc= 0.50292 val_roc= 0.90995 val_ap= 0.91896 time= 0.08302\n",
      "Epoch: 0184 train_loss= 1.39699 train_acc= 0.50312 val_roc= 0.91008 val_ap= 0.91884 time= 0.08404\n",
      "Epoch: 0185 train_loss= 1.44719 train_acc= 0.50288 val_roc= 0.91093 val_ap= 0.91974 time= 0.08393\n",
      "Epoch: 0186 train_loss= 1.42044 train_acc= 0.50251 val_roc= 0.91136 val_ap= 0.91993 time= 0.08318\n",
      "Epoch: 0187 train_loss= 1.42594 train_acc= 0.50354 val_roc= 0.91023 val_ap= 0.91860 time= 0.08383\n",
      "Epoch: 0188 train_loss= 1.48435 train_acc= 0.50412 val_roc= 0.90866 val_ap= 0.91656 time= 0.08305\n",
      "Epoch: 0189 train_loss= 1.45161 train_acc= 0.50152 val_roc= 0.90795 val_ap= 0.91554 time= 0.08194\n",
      "Epoch: 0190 train_loss= 1.46442 train_acc= 0.50223 val_roc= 0.90792 val_ap= 0.91480 time= 0.08399\n",
      "Epoch: 0191 train_loss= 1.43129 train_acc= 0.50334 val_roc= 0.90788 val_ap= 0.91433 time= 0.08306\n",
      "Epoch: 0192 train_loss= 1.45074 train_acc= 0.50305 val_roc= 0.90828 val_ap= 0.91463 time= 0.08393\n",
      "Epoch: 0193 train_loss= 1.42021 train_acc= 0.50257 val_roc= 0.90883 val_ap= 0.91505 time= 0.08408\n",
      "Epoch: 0194 train_loss= 1.48368 train_acc= 0.50320 val_roc= 0.90941 val_ap= 0.91654 time= 0.08395\n",
      "Epoch: 0195 train_loss= 1.43228 train_acc= 0.50319 val_roc= 0.90915 val_ap= 0.91731 time= 0.08265\n",
      "Epoch: 0196 train_loss= 1.41291 train_acc= 0.50330 val_roc= 0.90924 val_ap= 0.91761 time= 0.08220\n",
      "Epoch: 0197 train_loss= 1.41995 train_acc= 0.50283 val_roc= 0.90890 val_ap= 0.91720 time= 0.08788\n",
      "Epoch: 0198 train_loss= 1.43763 train_acc= 0.50325 val_roc= 0.90786 val_ap= 0.91631 time= 0.08164\n",
      "Epoch: 0199 train_loss= 1.45278 train_acc= 0.50261 val_roc= 0.90675 val_ap= 0.91540 time= 0.08303\n",
      "Epoch: 0200 train_loss= 1.43303 train_acc= 0.50377 val_roc= 0.90705 val_ap= 0.91592 time= 0.08363\n",
      "Optimization Finished!\n",
      "Test ROC score: 0.89518559459041\n",
      "Test AP score: 0.9065614828574703\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (200,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mE:\\jupyter\\gae\\gae\\train_debug.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[0my4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_roc_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'o-'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Train Loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'o-'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Train Accuracy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train Results'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2840\u001b[0m     return gca().plot(\n\u001b[0;32m   2841\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2842\u001b[1;33m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2843\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2844\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1741\u001b[0m         \"\"\"\n\u001b[0;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1743\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1744\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\vgae-tf\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[0;32m    400\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (200,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 改进损失函数后的 GCMAE\n",
    "%run train_debug.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vgae-tf] *",
   "language": "python",
   "name": "conda-env-vgae-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
